{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/how_to/#extraction\n",
    "# https://python.langchain.com/docs/tutorials/extraction/\n",
    "%pip install --upgrade --quiet typing langchain langchain_core pydantic langchain-community langchain_experimental langchain_ollama neo4j langchain_neo4j yfiles_jupyter_graphs jupyterlab ipywidgets jupyterlab-widgets langchain_ollama llama-cpp-python json_repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate neo4j instance.\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "graph = Neo4jGraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Schema\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"The color of the person's hair if known\"\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"Height measured in meters\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about people.\"\"\"\n",
    "\n",
    "    # Creates a model so that we can extract multiple entities.\n",
    "    people: List[Person]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the extractor\n",
    "from typing import Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        # Please see the how-to about improving performance with\n",
    "        # reference examples.\n",
    "        # MessagesPlaceholder('examples'),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_15592\\3466569965.py:7: LangChainDeprecationWarning: The class `OllamaFunctions` was deprecated in LangChain 0.0.64 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = OllamaFunctions(model=llm_model, temperature=0, format=\"json\")\n"
     ]
    }
   ],
   "source": [
    "#Load LLM\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "\n",
    "llm_model=\"mistral:7b-instruct-v0.3-q8_0\" #mistral:7b-instruct-v0.3-q8_0, llama3.1:8b-instruct-q8_0, llama3.2:3b-instruct-fp16\n",
    "\n",
    "llm = OllamaFunctions(model=llm_model, temperature=0, format=\"json\")\n",
    "# llm = ChatOllama(model=llm_model, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading via LlammaCPP\n",
    "# # from langchain_community.llms import LlamaCpp\n",
    "# from langchain_community.chat_models import ChatLlamaCpp\n",
    "# from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "\n",
    "# # https://github.com/langchain-ai/langchain/issues/25318\n",
    "# # https://github.com/langchain-ai/langchainjs/issues/6051\n",
    "# llm = ChatLlamaCpp(\n",
    "#     model_path=\"/home/ubuntu/repos/gguf/llama3_1_8b_f16.gguf\", #\"/home/ubuntu/repos/gguf/llama3_2_3b_q8_0.gguf\", mistral_7b_f16.gguf, llama3_1_8b_f16.gguf\n",
    "#     n_gpu_layers=-1,\n",
    "#     temperature=0,\n",
    "#     echo='True',\n",
    "#     grammar='json',\n",
    "#     n_batch=1,\n",
    "#     n_ctx=2048,\n",
    "#     f16_kv=False,\n",
    "#     # callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "#     # verbose=True,\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Jeff', hair_color='black', height_in_meters=None), Person(name='Anna', hair_color='black', height_in_meters=None)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(schema=Data)\n",
    "text = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load text instead\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import TokenTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(file_path=\"dummytext.txt\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100) #or TokenTextSplitter\n",
    "documents = text_splitter.split_documents(documents=docs)\n",
    "\n",
    "#see https://python.langchain.com/docs/how_to/extraction_long_text/ for more efficient parallel runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert raw unstructured text into graph documents.\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "llm_transformer = LLMGraphTransformer(llm=llm) #, ignore_tool_usage=True\n",
    "\n",
    "#if filtering is required.\n",
    "# llm_transformer_filtered = LLMGraphTransformer(\n",
    "#     llm=llm,\n",
    "#     allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "#     allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    "# )\n",
    "# graph_documents_filtered = llm_transformer_filtered.convert_to_graph_documents(\n",
    "#     documents\n",
    "# )\n",
    "# print(f\"Nodes:{graph_documents_filtered[0].nodes}\")\n",
    "# print(f\"Relationships:{graph_documents_filtered[0].relationships}\")\n",
    "\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_documents:nodes=[Node(id='Giovanni Caruso', type='Person', properties={}), Node(id='Maria', type='Person', properties={}), Node(id='Santa Caterina', type='Location', properties={}), Node(id='Sicily', type='Location', properties={}), Node(id='Caruso Family', type='Family', properties={})] relationships=[Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Maria', type='Person', properties={}), type='MARRIED', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Santa Caterina', type='Location', properties={}), type='RESIDED_IN', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Sicily', type='Location', properties={}), type='RESIDED_IN', properties={}), Relationship(source=Node(id='Caruso Family', type='Family', properties={}), target=Node(id='Giovanni Caruso', type='Person', properties={}), type='FAMILY_MEMBER', properties={}), Relationship(source=Node(id='Caruso Family', type='Family', properties={}), target=Node(id='Maria', type='Person', properties={}), type='FAMILY_MEMBER', properties={})] source=Document(metadata={'source': 'dummytext.txt'}, page_content=\"1. The Story of Amicoâ€™s Family: A Legacy of Love and Tradition\\nIn the idyllic village of Santa Caterina, amidst the rolling hills and sun-kissed landscapes of Sicily, lies the genesis of the Caruso family, a lineage intertwined with the island's rich culinary tapestry. The Carusos were not mere inhabitants of the land; they were the keepers of a culinary heritage that spanned generations. Each family member contributed their unique flair, crafting a narrative of flavors that reflected their diverse experiences and deep-seated love for food.\\n\\nGiovanni Caruso and Maria: The Founding Generation\")\n",
      "Nodes:[Node(id='Giovanni Caruso', type='Person', properties={}), Node(id='Maria', type='Person', properties={}), Node(id='Santa Caterina', type='Location', properties={}), Node(id='Sicily', type='Location', properties={}), Node(id='Caruso Family', type='Family', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Maria', type='Person', properties={}), type='MARRIED', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Santa Caterina', type='Location', properties={}), type='RESIDED_IN', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Sicily', type='Location', properties={}), type='RESIDED_IN', properties={}), Relationship(source=Node(id='Caruso Family', type='Family', properties={}), target=Node(id='Giovanni Caruso', type='Person', properties={}), type='FAMILY_MEMBER', properties={}), Relationship(source=Node(id='Caruso Family', type='Family', properties={}), target=Node(id='Maria', type='Person', properties={}), type='FAMILY_MEMBER', properties={})]\n",
      "[Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Maria', type='Person', properties={}), type='MARRIED', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Santa Caterina', type='Location', properties={}), type='RESIDED_IN', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Sicily', type='Location', properties={}), type='RESIDED_IN', properties={}), Relationship(source=Node(id='Caruso Family', type='Family', properties={}), target=Node(id='Giovanni Caruso', type='Person', properties={}), type='FAMILY_MEMBER', properties={}), Relationship(source=Node(id='Caruso Family', type='Family', properties={}), target=Node(id='Maria', type='Person', properties={}), type='FAMILY_MEMBER', properties={})]\n",
      "[Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Maria', type='Person', properties={}), type='SPOUSE', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Santa Caterina', type='Location', properties={}), type='RESIDES_IN', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Olives', type='Product', properties={}), type='PRODUCES', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Grapes', type='Product', properties={}), type='PRODUCES', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Oils', type='Product', properties={}), type='PRODUCES', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Wines', type='Product', properties={}), type='PRODUCES', properties={}), Relationship(source=Node(id='Maria', type='Person', properties={}), target=Node(id='Kitchen', type='Location', properties={}), type='WORKS_IN', properties={}), Relationship(source=Node(id='Maria', type='Person', properties={}), target=Node(id='Stews', type='Food', properties={}), type='COOKS', properties={}), Relationship(source=Node(id='Maria', type='Person', properties={}), target=Node(id='Pastries', type='Food', properties={}), type='COOKS', properties={})]\n"
     ]
    }
   ],
   "source": [
    "#view the contents\n",
    "print(f\"graph_documents:{graph_documents[0]}\")\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")\n",
    "\n",
    "doc = graph_documents[0:2]\n",
    "non_empty_nodes = [doc for doc in doc if doc.nodes]\n",
    "non_empty_rel = [doc for doc in doc if doc.relationships]\n",
    "\n",
    "# for graph_document in non_empty_nodes:\n",
    "#     print(graph_document.nodes)\n",
    "\n",
    "for doc in non_empty_rel:\n",
    "    print(doc.relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from neo4j import GraphDatabase, Driver\n",
    "\n",
    "# Add contents into neo4j database\n",
    "driver = GraphDatabase.driver(\n",
    "        uri = os.environ[\"NEO4J_URI\"],\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
    "    )\n",
    "\n",
    "def clear_database(tx):\n",
    "    tx.run(\"\"\"\n",
    "        MATCH (n)\n",
    "        DETACH DELETE n\n",
    "    \"\"\")    \n",
    "\n",
    "with driver.session() as session:\n",
    "    session.execute_write(clear_database)\n",
    "\n",
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aae42d689184ff1b70ad7e89ab92d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from neo4j import GraphDatabase, Driver\n",
    "\n",
    "default_cypher = \"MATCH (s)-[r]->(t) WHERE type(r) <> 'MENTIONS'RETURN s,r,t\"\n",
    "\n",
    "def showGraph(cypher: str = default_cypher):\n",
    "    # create a neo4j session to run queries\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri = os.environ[\"NEO4J_URI\"],\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
    "                os.environ[\"NEO4J_PASSWORD\"]))\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph = session.run(cypher).graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    #display(widget)\n",
    "    return widget\n",
    "\n",
    "showGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "- **Document**\n",
      "  - `id`: STRING Example: \"0676ad75015a754a3acc7987d8dc0cfb\"\n",
      "  - `source`: STRING Available options: ['dummytext.txt']\n",
      "  - `text`: STRING Example: \"4. Cultural and Culinary Festivals  The Carusos be\"\n",
      "- **Person**\n",
      "  - `id`: STRING Example: \"Giovanni Caruso\"\n",
      "- **Location**\n",
      "  - `id`: STRING Available options: ['Santa Caterina', 'Sicily', 'Village', 'Italy', 'Tuscany', 'New York City', 'Rome', 'Los Angeles']\n",
      "- **Family**\n",
      "  - `id`: STRING Available options: ['Caruso Family', 'Caruso_Family']\n",
      "- **Culinary_style**\n",
      "  - `id`: STRING Available options: [\"Amico'S Signature Style\"]\n",
      "- **Place**\n",
      "  - `id`: STRING Available options: ['Kitchen', 'Trattoria', 'Community Kitchens']\n",
      "- **Food**\n",
      "  - `id`: STRING Available options: ['Caponata', 'Fresh_Pasta']\n",
      "- **Restaurant**\n",
      "  - `id`: STRING Available options: ['La Dolce Vita', 'La Terra Di Siena', 'Bella Vita']\n",
      "- **Program**\n",
      "  - `id`: STRING Available options: ['Culinary Workshops And Mentorship Programs']\n",
      "- **Organization**\n",
      "  - `id`: STRING Available options: ['Caruso Family', 'Carusos', 'Local_Farmers_And_Producers']\n",
      "- **Initiative**\n",
      "  - `id`: STRING Available options: ['Farm-To-Table_Initiative']\n",
      "- **Concept**\n",
      "  - `id`: STRING Available options: ['Art', 'Food', 'Environmental_Sustainability', 'Local_Economy']\n",
      "- **Produce**\n",
      "  - `id`: STRING Available options: ['Seasonal_Produce', 'Organic_Produce']\n",
      "- **Persongroup**\n",
      "  - `id`: STRING Available options: ['Homeless', 'Low-Income Families', 'Patrons']\n",
      "- **Event**\n",
      "  - `id`: STRING Available options: ['Live_Performances', 'Cooking_Demonstrations', 'Exhibitions', 'Events', 'Food Drives']\n",
      "- **Organizationgroup**\n",
      "  - `id`: STRING Available options: ['Local Businesses']\n",
      "- **Culture**\n",
      "  - `id`: STRING Available options: ['Sicilian_Culture']\n",
      "- **Cuisine**\n",
      "  - `id`: STRING Available options: ['International_Cuisines']\n",
      "- **Market**\n",
      "  - `id`: STRING Available options: ['Artisan_Markets']\n",
      "- **Group**\n",
      "  - `id`: STRING Available options: ['Local Artists', 'Local Artisans', 'Performers']\n",
      "- **Artwork**\n",
      "  - `id`: STRING Available options: ['Paintings', 'Sculptures', 'Ceramics']\n",
      "- **Artform**\n",
      "  - `id`: STRING Available options: ['Music']\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Document)-[:MENTIONS]->(:Market)\n",
      "(:Document)-[:MENTIONS]->(:Event)\n",
      "(:Document)-[:MENTIONS]->(:Cuisine)\n",
      "(:Document)-[:MENTIONS]->(:Culture)\n",
      "(:Document)-[:MENTIONS]->(:Organization)\n",
      "(:Document)-[:MENTIONS]->(:Group)\n",
      "(:Document)-[:MENTIONS]->(:Artform)\n",
      "(:Document)-[:MENTIONS]->(:Artwork)\n",
      "(:Document)-[:MENTIONS]->(:Person)\n",
      "(:Document)-[:MENTIONS]->(:Concept)\n",
      "(:Document)-[:MENTIONS]->(:Family)\n",
      "(:Document)-[:MENTIONS]->(:Location)\n",
      "(:Document)-[:MENTIONS]->(:Culinary_style)\n",
      "(:Document)-[:MENTIONS]->(:Place)\n",
      "(:Document)-[:MENTIONS]->(:Food)\n",
      "(:Document)-[:MENTIONS]->(:Restaurant)\n",
      "(:Document)-[:MENTIONS]->(:Program)\n",
      "(:Document)-[:MENTIONS]->(:Initiative)\n",
      "(:Document)-[:MENTIONS]->(:Produce)\n",
      "(:Document)-[:MENTIONS]->(:Persongroup)\n",
      "(:Document)-[:MENTIONS]->(:Organizationgroup)\n",
      "(:Person)-[:SPOUSE]->(:Person)\n",
      "(:Person)-[:MARRIED]->(:Person)\n",
      "(:Person)-[:RESIDED_IN]->(:Location)\n",
      "(:Person)-[:RESIDES_IN]->(:Location)\n",
      "(:Person)-[:WORKS_IN]->(:Place)\n",
      "(:Person)-[:OWNS]->(:Restaurant)\n",
      "(:Person)-[:PARENT_CHILD]->(:Person)\n",
      "(:Person)-[:TRAVELED]->(:Location)\n",
      "(:Person)-[:CREATED]->(:Culinary_style)\n",
      "(:Person)-[:MARRIED_TO]->(:Person)\n",
      "(:Person)-[:CHILD_OF]->(:Person)\n",
      "(:Person)-[:OWNER]->(:Place)\n",
      "(:Person)-[:OWNER]->(:Restaurant)\n",
      "(:Person)-[:SPEARHEADED]->(:Initiative)\n",
      "(:Person)-[:COLLABORATED]->(:Organization)\n",
      "(:Person)-[:SISTER]->(:Person)\n",
      "(:Person)-[:GRANDMOTHER]->(:Person)\n",
      "(:Person)-[:MATRIARCH]->(:Family)\n",
      "(:Person)-[:MENTOR]->(:Person)\n",
      "(:Person)-[:MENTOR]->(:Food)\n",
      "(:Family)-[:DESTINATION]->(:Location)\n",
      "(:Family)-[:ORIGIN]->(:Location)\n",
      "(:Family)-[:FAMILY_MEMBER]->(:Person)\n",
      "(:Place)-[:LOCATION]->(:Person)\n",
      "(:Place)-[:MENTOR]->(:Person)\n",
      "(:Place)-[:SERVED]->(:Persongroup)\n",
      "(:Restaurant)-[:LOCATED_IN]->(:Location)\n",
      "(:Organization)-[:DESTINATION]->(:Location)\n",
      "(:Organization)-[:ORIGIN]->(:Location)\n",
      "(:Organization)-[:FAMILY_MEMBER]->(:Person)\n",
      "(:Organization)-[:CELEBRATES]->(:Culture)\n",
      "(:Organization)-[:SHOWCASES]->(:Cuisine)\n",
      "(:Organization)-[:ADVOCATE]->(:Person)\n",
      "(:Organization)-[:OWNED_BY]->(:Place)\n",
      "(:Organization)-[:ORGANIZED]->(:Event)\n",
      "(:Initiative)-[:PROMOTED]->(:Concept)\n",
      "(:Initiative)-[:SUPPORTED]->(:Concept)\n",
      "(:Event)-[:OCCURS_AT]->(:Organization)\n",
      "(:Event)-[:DONATED_BY]->(:Organizationgroup)\n",
      "(:Event)-[:DONATED_BY]->(:Persongroup)\n",
      "(:Market)-[:OCCURS_AT]->(:Organization)\n"
     ]
    }
   ],
   "source": [
    "#Display Neo4j Database Schema\n",
    "# https://python.langchain.com/docs/tutorials/graph/\n",
    "graph.refresh_schema()\n",
    "# print(graph.schema)\n",
    "enhanced_graph = Neo4jGraph(enhanced_schema=True)\n",
    "#more details\n",
    "print(enhanced_graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mTo find who Giovanni Caruso is, you would need to query for a Person node with the id 'Giovanni Caruso'. Here's an example Cypher statement:\n",
      "\n",
      "`MATCH (p:Person {id: 'Giovanni Caruso'}) RETURN p`\u001b[0m\n"
     ]
    },
    {
     "ename": "CypherSyntaxError",
     "evalue": "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'To': expected 'FOREACH', 'ALTER', 'CALL', 'USING PERIODIC COMMIT', 'CREATE', 'LOAD CSV', 'START DATABASE', 'STOP DATABASE', 'DEALLOCATE', 'DELETE', 'DENY', 'DETACH', 'DROP', 'DRYRUN', 'FINISH', 'GRANT', 'INSERT', 'MATCH', 'MERGE', 'NODETACH', 'OPTIONAL', 'REALLOCATE', 'REMOVE', 'RENAME', 'RETURN', 'REVOKE', 'ENABLE SERVER', 'SET', 'SHOW', 'TERMINATE', 'UNWIND', 'USE' or 'WITH' (line 1, column 1 (offset: 0))\n\"To find who Giovanni Caruso is, you would need to query for a Person node with the id 'Giovanni Caruso'. Here's an example Cypher statement:\"\n ^}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCypherSyntaxError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_neo4j\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphCypherQAChain\n\u001b[0;32m      5\u001b[0m chain \u001b[38;5;241m=\u001b[39m GraphCypherQAChain\u001b[38;5;241m.\u001b[39mfrom_llm(\n\u001b[0;32m      6\u001b[0m     graph\u001b[38;5;241m=\u001b[39menhanced_graph, llm\u001b[38;5;241m=\u001b[39mllm, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dangerous_requests\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWho is Giovanni Caruso\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m response\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_neo4j\\chains\\graph_qa\\cypher.py:400\u001b[0m, in \u001b[0;36mGraphCypherQAChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;66;03m# Retrieve and limit the number of results\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# Generated Cypher be null if query corrector identifies invalid schema\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generated_cypher:\n\u001b[1;32m--> 400\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_cypher\u001b[49m\u001b[43m)\u001b[49m[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k]\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     context \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_neo4j\\graphs\\neo4j_graph.py:447\u001b[0m, in \u001b[0;36mNeo4jGraph.query\u001b[1;34m(self, query, params)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneo4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Neo4jError\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 447\u001b[0m     data, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_database\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39mdata() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msanitize:\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_sync\\driver.py:969\u001b[0m, in \u001b[0;36mDriver.execute_query\u001b[1;34m(self, query_, parameters_, routing_, database_, impersonated_user_, bookmark_manager_, auth_, result_transformer_, **kwargs)\u001b[0m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    966\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid routing control value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrouting_\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    967\u001b[0m     )\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_pipelined_begin:\n\u001b[1;32m--> 969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_transaction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTelemetryAPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDRIVER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_transformer_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:581\u001b[0m, in \u001b[0;36mSession._run_transaction\u001b[1;34m(self, access_mode, api, transaction_function, args, kwargs)\u001b[0m\n\u001b[0;32m    579\u001b[0m tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtransaction_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;66;03m# if cancellation callback has not been called yet:\u001b[39;00m\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_work\\query.py:144\u001b[0m, in \u001b[0;36munit_of_work.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_sync\\driver.py:1305\u001b[0m, in \u001b[0;36m_work\u001b[1;34m(tx, query, parameters, transformer)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_work\u001b[39m(\n\u001b[0;32m   1300\u001b[0m     tx: ManagedTransaction,\n\u001b[0;32m   1301\u001b[0m     query: te\u001b[38;5;241m.\u001b[39mLiteralString,\n\u001b[0;32m   1302\u001b[0m     parameters: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, t\u001b[38;5;241m.\u001b[39mAny],\n\u001b[0;32m   1303\u001b[0m     transformer: t\u001b[38;5;241m.\u001b[39mCallable[[Result], t\u001b[38;5;241m.\u001b[39mUnion[_T]],\n\u001b[0;32m   1304\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m-> 1305\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mtx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformer(res)\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\transaction.py:195\u001b[0m, in \u001b[0;36mTransactionBase.run\u001b[1;34m(self, query, parameters, **kwparameters)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m    194\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwparameters)\n\u001b[1;32m--> 195\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tx_ready_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:175\u001b[0m, in \u001b[0;36mResult._tx_ready_run\u001b[1;34m(self, query, parameters)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tx_ready_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, parameters):\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# BEGIN+RUN does not carry any extra on the RUN message.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# BEGIN {extra}\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# RUN \"query\" {parameters} {extra}\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:231\u001b[0m, in \u001b[0;36mResult._run\u001b[1;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pull()\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:425\u001b[0m, in \u001b[0;36mResult._attach\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exhausted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 425\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:184\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutinefunction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__on_error)\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:994\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[0;32m    991\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[0;32m    992\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[0;32m    993\u001b[0m )\n\u001b[1;32m--> 994\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py:496\u001b[0m, in \u001b[0;36mBolt5x0._process_message\u001b[1;34m(self, tag, fields)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_state_manager\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbolt_states\u001b[38;5;241m.\u001b[39mFAILED\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n",
      "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:254\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[1;34m(self, metadata)\u001b[0m\n\u001b[0;32m    252\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandlers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    253\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[1;32m--> 254\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hydrate_error(metadata)\n",
      "\u001b[1;31mCypherSyntaxError\u001b[0m: {code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'To': expected 'FOREACH', 'ALTER', 'CALL', 'USING PERIODIC COMMIT', 'CREATE', 'LOAD CSV', 'START DATABASE', 'STOP DATABASE', 'DEALLOCATE', 'DELETE', 'DENY', 'DETACH', 'DROP', 'DRYRUN', 'FINISH', 'GRANT', 'INSERT', 'MATCH', 'MERGE', 'NODETACH', 'OPTIONAL', 'REALLOCATE', 'REMOVE', 'RENAME', 'RETURN', 'REVOKE', 'ENABLE SERVER', 'SET', 'SHOW', 'TERMINATE', 'UNWIND', 'USE' or 'WITH' (line 1, column 1 (offset: 0))\n\"To find who Giovanni Caruso is, you would need to query for a Person node with the id 'Giovanni Caruso'. Here's an example Cypher statement:\"\n ^}"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/tutorials/graph/\n",
    "\n",
    "from langchain_neo4j import GraphCypherQAChain\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    graph=enhanced_graph, llm=llm, verbose=True, allow_dangerous_requests=True\n",
    ")\n",
    "response = chain.invoke({\"query\": \"Who is Giovanni Caruso\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# his method configures keyword and vector search indexes for a hybrid search approach, targeting nodes labeled Document. Additionally, it calculates text embedding values if they are missing.\n",
    "#  The vector index can then be called with the similarity_search method.\n",
    "#     \n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"mxbai-embed-large\",\n",
    ")\n",
    "\n",
    "# from langchain_community.llms import LlamaCppEmbeddings\n",
    "# embeddings = LlamaCppEmbeddings(model_path=\"/home/ubuntu/repos/gguf/mxbai-embed-large-v1-f16.gguf\",\n",
    "#                               n_ctx=4096,\n",
    "#                               n_gpu_layers=-1,\n",
    "#                             #   n_threads=8,\n",
    "#                             #   n_batch=1000\n",
    "#                               )\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "\n",
    "vector_retriever = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph retriever starts by identifying relevant entities in the input. For simplicity, we instruct the LLM to identify people, organizations, and locations. To achieve this, we will use LCEL with the newly added with_structured_output method to achieve this.\n",
    "\n",
    "# Extract entities from text\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "entity_chain = prompt | llm.with_structured_output(Entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Great, now that we can detect entities in the question, let's use a full-text index to map them to the knowledge graph. First, we need to define a full-text index and a function that will generate full-text queries that allow a bit of misspelling, which we won't go into much detail here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_text_query(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a full-text search query for a given input string.\n",
    "\n",
    "    This function constructs a query string suitable for a full-text search.\n",
    "    It processes the input string by splitting it into words and appending a\n",
    "    similarity threshold (~2 changed characters) to each word, then combines\n",
    "    them using the AND operator. Useful for mapping entities from user questions\n",
    "    to database values, and allows for some misspelings.\n",
    "    \"\"\"\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~2 AND\"\n",
    "    full_text_query += f\" {words[-1]}~2\"\n",
    "    return full_text_query.strip()\n",
    "\n",
    "graph.query(\n",
    "    \"CREATE FULLTEXT INDEX `fulltext_entity_id` IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n",
    "\n",
    "# Fulltext index query\n",
    "def structured_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of entities mentioned\n",
    "    in the question\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke(question)\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structured_retriever function starts by detecting entities in the user question. Next, it iterates over the detected entities and uses a Cypher template to retrieve the neighborhood of relevant nodes. Let's test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucia - SISTER -> Antonio\n",
      "Lucia - MENTOR -> Amico\n",
      "Lucia - MENTOR -> Fresh_Pasta\n",
      "Lucia - MENTOR -> Caponata\n",
      "Lucia - MATRIARCH -> Caruso_Family\n",
      "Lucia - GRANDMOTHER -> Amico\n",
      "Kitchen - LOCATION -> Lucia\n",
      "Trattoria - MENTOR -> Nonna Lucia\n"
     ]
    }
   ],
   "source": [
    "print(structured_retriever(\"Who is Lucia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the unstructured and graph retriever to create the final context that will be passed to an LLM.\n",
    "\n",
    "def retriever(question: str):\n",
    "    print(f\"Search query: {question}\")\n",
    "    structured_data = structured_retriever(question)\n",
    "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
    "    final_data = f\"\"\"Structured data:\n",
    "{structured_data}\n",
    "Unstructured data:\n",
    "{\"#Document \". join(unstructured_data)}\n",
    "    \"\"\"\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from langchain_core.runnables import (\n",
    "    RunnableBranch,\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    "    ConfigurableField\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#Follow up Question prompts\n",
    "# Condense a chat history and follow-up question into a standalone question\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question,\n",
    "in its original language.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"  # noqa: E501\n",
    "CONDENSE_QUESTION_PROMPT = ChatPromptTemplate.from_template(_template)\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer\n",
    "\n",
    "_search_query = RunnableBranch(\n",
    "    # If input includes chat_history, we condense it with the follow-up question\n",
    "    (\n",
    "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
    "            run_name=\"HasChatHistoryCheck\"\n",
    "        ),  # Condense follow-up question and chat into a standalone_question\n",
    "        RunnablePassthrough.assign(\n",
    "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "        )\n",
    "        | CONDENSE_QUESTION_PROMPT\n",
    "        | ChatOllama(model = llm_model, temperature=0)\n",
    "        | StrOutputParser(),\n",
    "    ),\n",
    "    # Else, we have no chat history, so just pass through the question\n",
    "    RunnableLambda(lambda x : x[\"question\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Use natural language and be concise.\n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": _search_query | retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: Who is most powerful member in the family?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nonna Lucia, as the matriarch and mentor of the Caruso family, is considered the most powerful member due to her influence on the family's culinary traditions, values, and wisdom.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " chain.invoke({\"question\": \"Who is most powerful member in the family?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

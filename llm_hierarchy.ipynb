{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomasonjo/blogs/blob/master/llm/ms_graphrag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K7S1j3FOoi0",
        "outputId": "0e6fd76d-1b4e-4eda-8a02-95468cd8158f"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet langchain-community pandas langchain-experimental langchain-openai neo4j graphdatascience tiktoken retry seaborn matplotlib\n",
        "# https://github.com/tomasonjo/blogs/blob/master/llm/ms_graphrag.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmnDlh4BeFJM"
      },
      "source": [
        "# GraphRAG with Neo4j and LangChain: Constructing the Graph\n",
        "## Combine text extraction, network analysis, and LLM prompting and summarization for improved RAG accuracy\n",
        "\n",
        "I am always intrigued by new approaches to implementing Retrieval-Augmented Generation (RAG) over graphs, often called GraphRAG. However, it seems that everyone has a different implementation in mind when they hear the term GraphRAG. In this blog post, we will dive deep into the “From Local to Global GraphRAG” article and implementation by Microsoft researchers. We will cover the knowledge graph construction and summarization part and leave the retrievers for the next blog post. The researchers were so kind as to provide us with the code repository, and they have a [project page](https://www.microsoft.com/en-us/research/project/graphrag/) as well.\n",
        "\n",
        "The approach taken in the article mentioned above is quite interesting. As far as I understand, it involves using a knowledge graph as a step in the pipeline for condensing and combining information from multiple sources. Extracting entities and relationships from text is nothing new. However, the authors introduce a novel (at least to me) idea of summarizing condensed graph structure and information back as natural language text. The pipeline begins with input text from documents, which are processed to generate a graph. The graph is then converted back into natural language text, where the generated text contains condensed information about specific entities or graph communities previously spread across multiple documents.\n",
        "\n",
        "![title](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NWkjGfKvWyKJsXfj-HxVjA.png)\n",
        "\n",
        "At a very high level, the input to the GraphRAG pipeline are source documents containing various information. The documents are processed using an LLM to extract structured information about entities appearing in the papers along with their relationships. This extracted structured information is then used to construct a knowledge graph.\n",
        "\n",
        "The advantage of using a knowledge graph data representation is that it can quickly and straightforwardly combine information from multiple documents or data sources about particular entities. As mentioned, the knowledge graph is not the only data representation, though. After the knowledge graph has been constructed, they use a combination of graph algorithms and LLM prompting to generate natural language summaries of communities of entities found in the knowledge graph.\n",
        "\n",
        "These summaries then contain condensed information spreading across multiple data sources and documents for particular entities and communities.\n",
        "\n",
        "For a more detailed understanding of the pipeline, we can refer to the step-by-step description provided in the original paper.\n",
        "\n",
        "![title](https://miro.medium.com/v2/resize:fit:942/format:webp/1*xn10XHns9xQ1WLQxEaSA7w.png)\n",
        "\n",
        "Following is a high-level summary of the pipeline that we will use to reproduce their approach using Neo4j and LangChain.\n",
        "\n",
        "* Indexing — Graph Generation\n",
        "Source Documents to Text Chunks: Source documents are split into smaller text chunks for processing.\n",
        "* Text Chunks to Element Instances: Each text chunk is analyzed to extract entities and relationships, producing a list of tuples representing these elements.\n",
        "* Element Instances to Element Summaries: Extracted entities and relationships are summarized by the LLM into descriptive text blocks for each element.\n",
        "* Element Summaries to Graph Communities: These entity summaries form a graph, which is then partitioned into communities using algorithms like Leiden for hierarchical structure.\n",
        "* Graph Communities to Community Summaries: Summaries of each community are generated with the LLM to understand the dataset’s global topical structure and semantics.\n",
        "\n",
        "#### Retrieval — Answering\n",
        "\n",
        "* Community Summaries to Global Answers: Community summaries are used to answer a user query by generating intermediate answers, which are then aggregated into a final global answer.\n",
        "Note that my implementation was done before their code was available, so there might be slight differences in the underlying approach or LLM prompts being used. I’ll try to explain those differences as we go along.\n",
        "\n",
        "### Setting Up the Neo4j Environment\n",
        "We will use Neo4j as the underlying graph store. The easiest way to get started is to use a free instance of Neo4j Sandbox, which offers cloud instances of the Neo4j database with the Graph Data Science plugin installed. Alternatively, you can set up a local instance of the Neo4j database by downloading the Neo4j Desktop application and creating a local database instance. If you are using a local version, make sure to install both APOC and GDS plugins. For production setups, you can use the paid, managed AuraDS (Data Science) instance, which provides the GDS plugin.\n",
        "\n",
        "We start by creating a Neo4jGraph instance, which is the convenience wrapper we added to LangChain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wbCXrSxUPTIy"
      },
      "outputs": [],
      "source": [
        "#instantiate neo4j instance.\n",
        "from langchain_neo4j import Neo4jGraph\n",
        "graph = Neo4jGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2BE07dRfHf3"
      },
      "source": [
        "### Dataset\n",
        "We will use a news article dataset I created some time ago using Diffbot’s API. I have uploaded it to my GitHub for easier reuse:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VKwjKqPyP78d",
        "outputId": "0f470ee8-3298-4711-8bb1-57c495abd77e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "def num_tokens_from_string(string: str, model: str = \"gpt-4o\") -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "\n",
        "news = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/news_articles.csv\", nrows=20\n",
        ")\n",
        "news[\"tokens\"] = [\n",
        "    num_tokens_from_string(f\"{row['title']} {row['text']}\")\n",
        "    for i, row in news.iterrows()\n",
        "]\n",
        "# news.head(5)\n",
        "news = news[3:9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_nPbFIFfMqi"
      },
      "source": [
        "We have the title and text of the articles available, along with their publishing date and token count using the tiktoken library.\n",
        "\n",
        "### Text Chunking\n",
        "The text chunking step is crucial and significantly impacts downstream results. The paper authors found that using smaller text chunks results in extracting more entities overall.\n",
        "\n",
        "![title](https://miro.medium.com/v2/resize:fit:1120/format:webp/1*9HdF1xQ6Tm6dazOQBFvSvg.png)\n",
        "\n",
        "As you can see, using text chunks of 2,400 tokens results in fewer extracted entities than when they used 600 tokens. Additionally, they identified that LLMs might not extract all entities on the first run. In that case, they introduce a heuristics to perform the extraction multiple times. We will talk about that more in the next section.\n",
        "\n",
        "However, there are always trade-offs. Using smaller text chunks can result in losing the context and coreferences of specific entities spread across the documents. For example, if a document mentions “John” and “he” in separate sentences, breaking the text into smaller chunks might make it unclear that “he” refers to John. Some of the coreference issues can be solved using an overlap text chunking strategy, but not all of them.\n",
        "\n",
        "Let’s examine the size of our article texts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ebzDWs-io-Oj",
        "outputId": "3d4d390f-4450-4dfc-ce3f-5d512a6851b8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "sns.histplot(news[\"tokens\"], kde=False)\n",
        "plt.title('Distribution of chunk sizes')\n",
        "plt.xlabel('Token count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tBXEXvRjQVL"
      },
      "source": [
        "The distribution of article token counts is approximately normal, with a peak of around 400 tokens. The frequency of chunks gradually increases up to this peak, then decreases symmetrically, indicating most text chunks are near the 400-token mark.\n",
        "\n",
        "Due to this distribution, we will not perform any text chunking here to avoid coreference issues. By default, the GraphRAG project uses chunk sizes of 300 tokens with 100 tokens of overlap.\n",
        "\n",
        "### Extracting Nodes and Relationships\n",
        "The next step is constructing knowledge from text chunks. For this use case, we use an LLM to extract structured information in the form of nodes and relationships from the text. You can examine the LLM prompt the authors used in the paper. They have LLM prompts where we can predefine node labels if needed, but by default, that’s optional. Additionally, the extracted relationships in the original documentation don’t really have a type, only a description. I imagine the reason behind this choice is to allow the LLM to extract and retain richer and more nuanced information as relationships. But it’s difficult to have a clean knowledge graph with no relationship-type specifications (the descriptions could go into a property).\n",
        "\n",
        "In our implementation, we will use the LLMGraphTransformer, which is available in the LangChain library. Instead of using pure prompt engineering, as the implementation in the article paper does, the LLMGraphTransformer uses the built-in function calling support to extract structured information (structured output LLMs in LangChain). You can inspect the system prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "INfxdQRCPxyW"
      },
      "outputs": [],
      "source": [
        "#Load LLM\n",
        "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
        "# from ollama_functions import OllamaFunctions\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
        "\n",
        "llm_model=\"mistral:7b-instruct-v0.3-q8_0\" #mistral:7b-instruct-v0.3-q8_0, llama3.1:8b-instruct-q8_0, llama3.2:3b-instruct-fp16 llama3.1:8b-instruct-q5_K_M\n",
        "\n",
        "# llm = OllamaFunctions(model=llm_model, temperature=0, format=\"json\")\n",
        "llm = ChatOllama(model=llm_model, temperature=0)\n",
        "\n",
        "llm_transformer = LLMGraphTransformer(\n",
        "    llm=llm,\n",
        "    node_properties=[\"description\"],\n",
        "    relationship_properties=[\"description\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "doaut5qvTr36"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from langchain_community.graphs.graph_document import GraphDocument\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import TokenTextSplitter, RecursiveCharacterTextSplitter\n",
        "\n",
        "def process_text(text: str) -> List[GraphDocument]:\n",
        "    doc = Document(page_content=text)\n",
        "    # print(doc)\n",
        "    # text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
        "    # doc = text_splitter.split_documents(documents=raw_doc)\n",
        "    return llm_transformer.convert_to_graph_documents([doc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsdJJlNpfjuy"
      },
      "source": [
        "In this example, we use GPT-4o for graph extraction. The authors specifically instruct the LLM to extract entities and relationships and their descriptions. With the LangChain implementation, you can use the node_propertiesand relationship_propertiesattributes to specify which node or relationship properties you want the LLM to extract.\n",
        "\n",
        "The difference with the LLMGraphTransformer implementation is that all node or relationship properties are optional, so not all nodes will have the descriptionproperty. If we wanted, we could define a custom extraction to have a mandatory descriptionproperty, but we will skip that in this implementation.\n",
        "\n",
        "We will parallelize the requests to make the graph extraction faster and store results to Neo4j:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase, Driver\n",
        "import os\n",
        "\n",
        "# clear before adding the same source\n",
        "driver = GraphDatabase.driver(\n",
        "        uri = os.environ[\"NEO4J_URI\"],\n",
        "        auth = (os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
        "    )\n",
        "\n",
        "def clear_database(tx):\n",
        "    tx.run(\"\"\"\n",
        "        MATCH (n)\n",
        "        DETACH DELETE n\n",
        "    \"\"\")    \n",
        "\n",
        "with driver.session() as session:\n",
        "    session.execute_write(clear_database)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy9GaXqXRrQu",
        "outputId": "4e558b9b-2f02-4687-fe74-ce21259a9b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Epic’s latest tool can animate hyperrealistic MetaHumans with an iPhone Today, Epic is releasing a new tool designed to capture an actor’s facial performance using a device as simple as an iPhone and apply it to a hyperrealistic “MetaHuman” in the Unreal Engine in “minutes.” The feature, dubbed MetaHuman Animator, was detailed at the Game Developers Conference in March but is now available for developers to try out for themselves. Epic has also released a new video today produced by one of its internal teams to show what the tool is capable of.\n",
            "While Epic’s short film shows off some impressively subtle facial animation, the big benefit the company is emphasizing is the speed with which MetaHuman Animator produces results. “The animation is produced locally using GPU hardware, with the final animation available in minutes,” the company’s press release reads. That has the potential to not just save a studio money by making performance capture more efficient but also, Epic argues, it could allow them to experiment and be more creative.\n",
            "“Need an actor to give you more, dig into a different emotion, or simply explore a new direction?” Epic’s press release asks. “Have them do another take. You’ll be able to review the results in about the time it takes to make a cup of coffee.” Facial animation can be applied to a MetaHuman character “in just a few clicks,” Epic says, and the system is even smart enough to animate a character’s tongue based on the performance’s audio.\n",
            "Performance capture using iPhones has been possible in the Unreal Engine since at least 2020 with the launch of Epic’s Live Link Face iOS app, but now, it’s combined with the high level of detail promised by Epic’s MetaHuman technology. As well as working on the iPhone 12 and up (which is capable of capturing both video and depth data), Epic says MetaHuman Animator can also be used with “existing vertical stereo head-mounted camera [systems] to achieve even greater fidelity.”\n",
            "Epic says the Blue Dot short film released today should give some idea of what its animation tool is capable of. It was produced by Epic Games’ 3Lateral team and stars actor Radivoje Bukvić delivering a monologue based on a poem by Mika Antić. Although Epic says it’s possible to tweak animation post-capture, it claims “minimal interventions” were made on top of the MetaHuman Animator’s performance capture to achieve these results.\n",
            "If you want to learn more, Epic has released an instructional video on how to use the tool. Documentation is also available via the MetaHuman hub on the Epic Developer Community.'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing documents:   0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing documents:  17%|█▋        | 1/6 [04:54<24:34, 294.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='EU to Ban Huawei, ZTE from Internal Commission Networks The European Commission is planning to ban equipment from Chinese vendors Huawei Technologies Co. and ZTE Corp. from its own internal telecommunications networks, people familiar with the matter said.\n",
            "The ban comes ahead of an anticipated update to the European Union’s guidance on 5G mobile networks within the bloc that’s expected to more forcefully encourage members to phase out equipment from the companies, which it considers high risk, the people said, asking not to be identified because the plan isn’t yet public.\n",
            "As the relationship between the US and its allies and China has deteriorated, countries have blocked Chinese technology from their core telecommunications networks because of spying concerns. The move is similar to the commission’s decision to block its staff from using TikTok Inc. over security concerns related to the social-media app’s data-collection practices.\n",
            "Read More: TikTok Banned From EU Commission Phones Amid Security Fears\n",
            "In the EU’s review of the 5G “toolbox,” the commission will say that publicly excluding Huawei and ZTE from national networks is justified and will explicitly call out Huawei and ZTE as high-risk vendors by name for the first time. The majority of countries have yet to ban the two Chinese vendors from their networks.\n",
            "Representatives for Huawei and ZTE didn’t immediately respond to requests for comment.\n",
            "— With assistance by Thomas Seal and Alberto Nardelli'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing documents:  33%|███▎      | 2/6 [05:00<08:18, 124.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Arsenal have Rice bid rejected, new Premier League fixtures released, Man United out of Harry Kane race, Chelsea reject Mason Mount bid Jude Bellingham has also insisted his move to Real Madrid had nothing to do with money, as he explained how his transfer was wrapped up so quickly.\n",
            "“Money is not a thing for me,” he said.\n",
            "“I dont think about money at all when I make these kinds of decisions. I never have and I never will. I play the game purely out of love.\n",
            "“I spoke with people from Real Madrid when I was given permission by Borussia Dortmund and I love the feeling I got from the club. I couldn’t hide it. I told them straight away what I felt and after that happened on Monday it all happened quickly.”\n",
            "He also opened up on how he was given the No.5 shirt, which was worn by defender Jesus Vallejo last season, and what it means to him to have Zidane’s old number on his back.\n",
            "“For a start I’d like to thank Jesus Vallejo for letting me wear the No.5,” he explained.\n",
            "“I contacted him just to see if it was OK with him and he was just a brilliant guy, he let me wear it and was just so nice about it, so I’m very grateful to him.\n",
            "“I’ve said in many interviews how much I admire Zidane, the legacy he has at the club and the legacy of his number.\n",
            "“I’m not trying to be the same as him, I’m just trying to be Jude, but it’s definitely a bit of a homage to how great he was.\n",
            "“As for the 22, it’s a number that has a lot of meaning to me and in my heart I’m still a 22, I’m just wearing the No.5 on my back.\n",
            "“We’ll see what happens in the future, but right now I’m really happy to be given this honour of wearing this number.”'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing documents:  50%|█████     | 3/6 [05:06<03:31, 70.44s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Ryanair sacks chief pilot over sexual misconduct claims Reuters\n",
            "Ryanair has sacked its chief pilot after an investigation into his alleged sexual harassment of female colleagues.\n",
            "The airline told staff that he had been fired for \"a pattern of repeated inappropriate and unacceptable behaviour towards a number of female pilots\".\n",
            "The chief pilot, named in reports as Aidan Murray was appointed in 2020 and had been with the airline for 28 years.\n",
            "Ryanair declined to comment \"on queries relating to individual employees\".\n",
            "According to The Independent, Mr Murray allegedly harassed nine junior colleagues, including sending text messages to some with comments on their bodies.\n",
            "Mr Murray, 58, is also accused of altering flight rosters to fly with certain female pilots.\n",
            "In a note to staff, Ryanair's chief people officer, Darrell Hughes, said Mr Murray's employment had been \"terminated with immediate effect\".\n",
            "An investigation found his behaviour \"was in breach of our anti-harassment policy\". Ryanair said staff should be able to come to work \"in a safe and secure environment\".\n",
            "\"We would ask all of you to respect the privacy and integrity of those brave individuals who came forward to assist us in this investigation,\" Mr Hughes added.\n",
            "The Financial Times reported that Mr Murray has seven days to launch an appeal against his dismissal.\n",
            "The BBC has attempted to contact Mr Murray for comment.\n",
            "The job of chief pilot is an important one. The holder is both a highly qualified airline captain and a manager, responsible for overseeing other pilots based at a hub airport.\n",
            "They are usually in charge of issues such as training, flight coordination and rostering as well as addressing personal issues. They can also represent the airline in disciplinary issues.\n",
            "As such, they have a lot of power over their fellow pilots, particularly more junior ones seeking promotions.\n",
            "The suggestion that someone in this position might be abusing their power - and behaving in an \"inappropriate and unacceptable\" way towards female staff - is therefore a very serious charge.\n",
            "It's important to note that we haven't heard the other side of the story. But it appears that whistleblowers have come forward - and have been listened to.\n",
            "Against that background, the dismissal should come as no surprise.\n",
            "A report last year by the Royal Aeronautical Society into discrimination and lack of diversity in airline pilot training found \"extremely concerning\" reports of sexism and sexual harassment by many female pilots.\n",
            "Although many had positive comments on their training, reports of sexism and harassment ranged from \"banter\" to \"uncomfortable advances from male trainers\".\n",
            "Related Topics\n",
            "Sexual harassment\n",
            "Ryanair\n",
            "More on this story\n",
            "Pilot, 15, wants to inspire more women into gliding\n",
            "2 hours ago\n",
            "Heathrow workers call off first summer strikes\n",
            "2 days ago'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing documents:  67%|██████▋   | 4/6 [05:11<01:29, 44.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='KeyBank’s American Fork Branch Celebrates One Year Anniversary CLEVELAND, UT / ACCESSWIRE / June 15, 2023 / KeyBank recently commemorated the one-year anniversary of its American Fork branch - the company's first new branch in the Western half of the U.S. in more than a decade. The celebration included a networking event with the branch's business clients and the American Fork Chamber of Commerce, as well as a $10,000 donation to the Five.12 Foundation.\n",
            "\"We've had a great first year in American Fork,\" said Drew Yergensen, KeyBank Utah market president and commercial banking leader. \"We have really enjoyed meeting and working more closely with our new neighbors, clients and community partners, and we look forward to strengthening those relationships even further in the coming years.\"\n",
            "The American Fork branch highlights KeyBank's state-of-the-art financial wellness center model, which is staffed with financial wellness consultants rather than a traditional teller line. All transactions are completed at desks, where consultants also conduct comprehensive financial wellness reviews and discussions. Clients can also meet with specialists in mortgage, investments, business banking and more at the location.\n",
            "The branch features digital video screens and a client hospitality space that also serves as an area for financial seminars and group presentations with clients and the public, as well as a drive-up teller line, ATM and complimentary parking. In addition to helping individuals and families achieve their financial goals, the branch also serves clients seeking to develop and grow businesses in the area.\n",
            "\"We are here to help the community of American Fork with all of their banking and small business needs,\" said Jason Scorup, KeyBank American Fork branch manager. \"We also take pride in the positive impact we've had by giving back to community partners like the Five.12 Foundation, and we look forward to building even more community partnerships in and around American Fork.\"\n",
            "Based in Alpine, Utah, the Five.12 Foundation organizes and distributes weekend food bags to students in need at four American Fork elementary schools, including Greenwood, Forbes, Barratt and Shelley.\n",
            "The full-service branch is located at 717 West Main in American Fork, directly off of the 278 exit from I-15.\n",
            "CONTACT:\n",
            "Laura Suter | Regional Communications Manager | 206.343.6953 | laura_suter@keybank.com\n",
            "ABOUT KEYBANK\n",
            "KeyCorp's roots trace back nearly 200 years to Albany, New York. Headquartered in Cleveland, Ohio, Key is one of the nation's largest bank-based financial services companies, with assets of approximately $198 billion at March 31, 2023. Key provides deposit, lending, cash management, and investment services to individuals and businesses in 15 states under the name KeyBank National Association through a network of approximately 1,000 branches and approximately 1,300 ATMs. Key also provides a broad range of sophisticated corporate and investment banking products, such as merger and acquisition advice, public and private debt and equity, syndications and derivatives to middle market companies in selected industries throughout the United States under the KeyBanc Capital Markets trade name. For more information, visit https://www.key.com/. KeyBank is Member FDIC.\n",
            "###\n",
            "View additional multimedia and more ESG storytelling from KeyBank on 3blmedia.com.\n",
            "Contact Info:\n",
            "Spokesperson: KeyBank\n",
            "Website: https://www.3blmedia.com/profiles/keybank\n",
            "Email: info@3blmedia.com\n",
            "SOURCE: KeyBank\n",
            "View source version on accesswire.com:\n",
            "https://www.accesswire.com/761502/KeyBanks-American-Fork-Branch-Celebrates-One-Year-Anniversary\n",
            "Serious News for Serious Traders! Try StreetInsider.com Premium Free!\n",
            "You May Also Be Interested In'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing documents:  83%|████████▎ | 5/6 [05:16<00:30, 30.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Vivo X90s Officially Teased, Tipped to Run on New MediaTek Dimensity 9200+ SoC Vivo X90s has been teased by Jia Jingdong, Vivo's Vice President and General Manager of Product Strategy via Weibo on Thursday. The new smartphone has a design similar to its Vivo X90 series siblings — Vivo X90 and Vivo X90 Pro. The Vivo X90s is shown to have a Zeiss-tuned triple rear camera unit. The upcoming model is expected to retain the key specification of the Vivo X90. Meanwhile, Chinese tipsters have leaked the specifications of the upcoming handset. The Vivo X90s is said to run on MediaTek Dimensity 9200+ SoC and could be offered in four different colour options.\n",
            "Jia Jingdong posted an image of the Vivo X90s on the Chinese microblogging platform providing us a glimpse of the design from the rear. The render shows the handset in a white finish with rounded corners. The image suggests Zeiss branded triple rear cameras on the rear panel along with an LED flash. It seems to have a glass back with the Vivo branding at the bottom.\n",
            "Vivo, however, didn't confirm the exact launch date or key specifications of the Vivo X90s.\n",
            "Separately, several Chinese tipsters posted specifications of the upcoming Vivo X90s on Weibo. According to the tipsters, the handset will be powered by the latest MediaTek Dimensity 9200+ SoC. This would be an upgrade over the MediaTek Dimensity 9200 SoC found on the vanilla Vivo X90. The new model is said to offer Wi-Fi 7 connectivity and could be offered in black, blue, green, red, and white colour options. The Vivo X90, in contrast, has Wi-Fi 6 and is available in China Red, Ice Blue, and Original Black (translated from Chinese) in China.\n",
            "A TENAA listing from May revealed the specifications of the Vivo X90s. As per the listing, it will have a 6.78-inch 1.5K (1,280 x 2,800 pixels) curved AMOLED display. The screen has a centre-aligned hole-punch cutout at the top. It is listed to carry up to 16GB of RAM along with up to 1TB of inbuilt storage.\n",
            "Oppo, OnePlus, Realme to Operate as Separate Entities in India: Report\n",
            "The triple rear camera setup of the handset could include a 50-megapixel main camera sensor, accompanied by a 12-megapixel ultra-wide lens, and a 12-megapixel portrait sensor. It is said to pack a 32-megapixel selfie camera as well. Vivo is expected to provide a 4,690mAh battery on the Vivo X90s.\n",
            "The Vivo X90 Pro has finally made its debut in India, but is the company's flagship smartphone for 2023 equipped with enough upgrades over its predecessor? We discuss this and more on Orbital, the Gadgets 360 podcast. Orbital is available on Spotify, Gaana, JioSaavn, Google Podcasts, Apple Podcasts, Amazon Music and wherever you get your podcasts.\n",
            "Affiliate links may be automatically generated - see our ethics statement for details.\n",
            "For the latest tech news and reviews, follow Gadgets 360 on Twitter, Facebook, and Google News. For the latest videos on gadgets and tech, subscribe to our YouTube channel.'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing documents: 100%|██████████| 6/6 [05:23<00:00, 53.95s/it]\n"
          ]
        }
      ],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "MAX_WORKERS = 1\n",
        "NUM_ARTICLES = 6 #2000\n",
        "graph_documents = []\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "    # Submitting all tasks and creating a list of future objects\n",
        "    futures = [\n",
        "        executor.submit(process_text, f\"{row['title']} {row['text']}\")\n",
        "        for i, row in news.head(NUM_ARTICLES).iterrows()\n",
        "    ]\n",
        "\n",
        "    for future in tqdm(\n",
        "        as_completed(futures), total=len(futures), desc=\"Processing documents\"\n",
        "    ):\n",
        "        graph_document = future.result()\n",
        "        graph_documents.extend(graph_document)\n",
        "\n",
        "graph.add_graph_documents(\n",
        "    graph_documents,\n",
        "    baseEntityLabel=True,\n",
        "    include_source=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load text instead\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import TokenTextSplitter, RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = TextLoader(file_path=\"dummytext.txt\")\n",
        "docs = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100) #or TokenTextSplitter\n",
        "documents = text_splitter.split_documents(documents=docs)\n",
        "\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(documents); \n",
        "graph.add_graph_documents(\n",
        "    graph_documents,\n",
        "    baseEntityLabel=True,\n",
        "    include_source=True\n",
        ")\n",
        "#see https://python.langchain.com/docs/how_to/extraction_long_text/ for more efficient parallel runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPqW-TpOftgc"
      },
      "source": [
        "In this example, we extract graph information from 2,000 articles and store results to Neo4j. We have extracted around 13,000 entities and 16,000 relationships. Here is an example of an extracted document in the graph.\n",
        "\n",
        "\n",
        "![title](https://miro.medium.com/v2/resize:fit:952/format:webp/1*pj-V-XHmVaJE5SsOtvqOqw.png)\n",
        "\n",
        "It takes about 35 (+/- 5) minutes to complete extraction and costs about $30 with GPT-4o.\n",
        "\n",
        "In this step, the authors introduce heuristics to decide whether to extract graph information in more than one pass. For simplicity’s sake, we will only do one pass. However, if we wanted to do multiple passes, we could put the first extraction results as conversational history and simply [instruct the LLM that many entities are missing](https://github.com/microsoft/graphrag/blob/main/graphrag/index/graph/extractors/claims/prompts.py#L60), and it should extract more, like the GraphRAG authors do.\n",
        "\n",
        "Previously, I mentioned how vital text chunk size is and how it affects the number of entities extracted. Since we didn’t perform any additional text chunking, we can evaluate the distribution of extracted entities based on text chunk size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "u2Qz8jYbpd8Z",
        "outputId": "679aa177-4852-4e77-b072-5e540ba17d48"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "entity_dist = graph.query(\n",
        "    \"\"\"\n",
        "MATCH (d:Document)\n",
        "RETURN d.text AS text,\n",
        "       count {(d)-[:MENTIONS]->()} AS entity_count\n",
        "\"\"\"\n",
        ")\n",
        "entity_dist_df = pd.DataFrame.from_records(entity_dist)\n",
        "entity_dist_df[\"token_count\"] = [\n",
        "    num_tokens_from_string(str(el)) for el in entity_dist_df[\"text\"]\n",
        "]\n",
        "# Scatter plot with regression line\n",
        "sns.lmplot(\n",
        "    x=\"token_count\", y=\"entity_count\", data=entity_dist_df, line_kws={\"color\": \"red\"}\n",
        ")\n",
        "plt.title(\"Entity Count vs Token Count Distribution\")\n",
        "plt.xlabel(\"Token Count\")\n",
        "plt.ylabel(\"Entity Count\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyEy_AgFgDj6"
      },
      "source": [
        "The scatter plot shows that while there is a positive trend, indicated by the red line, the relationship is sublinear. Most data points cluster at lower entity counts, even as token counts increase. This indicates that the number of entities extracted does not scale proportionally with the size of the text chunks. Although some outliers exist, the general pattern shows that higher token counts do not consistently lead to higher entity counts. This validates the authors’ finding that lower text chunk sizes will extract more information.\n",
        "\n",
        "I also thought it would be interesting to inspect the node degree distributions of the constructed graph. The following code retrieves and visualizes node degree distributions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "eYhQaUkQOGyu",
        "outputId": "3fd9e277-2c1b-4d81-a35e-b5188c31977a"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'node_degree'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'node_degree'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m degree_dist_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(degree_dist)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate mean and median\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m mean_degree \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mdegree_dist_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnode_degree\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     13\u001b[0m percentiles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(degree_dist_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_degree\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m75\u001b[39m, \u001b[38;5;241m90\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create a histogram with a logarithmic scale\u001b[39;00m\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'node_degree'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "degree_dist = graph.query(\n",
        "    \"\"\"\n",
        "MATCH (e:__Entity__)\n",
        "RETURN count {(e)-[:!MENTIONS]-()} AS node_degree\n",
        "\"\"\"\n",
        ")\n",
        "degree_dist_df = pd.DataFrame.from_records(degree_dist)\n",
        "\n",
        "# Calculate mean and median\n",
        "mean_degree = np.mean(degree_dist_df['node_degree'])\n",
        "percentiles = np.percentile(degree_dist_df['node_degree'], [25, 50, 75, 90])\n",
        "# Create a histogram with a logarithmic scale\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(degree_dist_df['node_degree'], bins=50, kde=False, color='blue')\n",
        "# Use a logarithmic scale for the x-axis\n",
        "plt.yscale('log')\n",
        "# Adding labels and title\n",
        "plt.xlabel('Node Degree')\n",
        "plt.ylabel('Count (log scale)')\n",
        "plt.title('Node Degree Distribution')\n",
        "# Add mean, median, and percentile lines\n",
        "plt.axvline(mean_degree, color='red', linestyle='dashed', linewidth=1, label=f'Mean: {mean_degree:.2f}')\n",
        "plt.axvline(percentiles[0], color='purple', linestyle='dashed', linewidth=1, label=f'25th Percentile: {percentiles[0]:.2f}')\n",
        "plt.axvline(percentiles[1], color='orange', linestyle='dashed', linewidth=1, label=f'50th Percentile: {percentiles[1]:.2f}')\n",
        "plt.axvline(percentiles[2], color='yellow', linestyle='dashed', linewidth=1, label=f'75th Percentile: {percentiles[2]:.2f}')\n",
        "plt.axvline(percentiles[3], color='brown', linestyle='dashed', linewidth=1, label=f'90th Percentile: {percentiles[3]:.2f}')\n",
        "# Add legend\n",
        "plt.legend()\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE3oNAl6gIHH"
      },
      "source": [
        "The node degree distribution follows a power-law pattern, indicating most nodes have very few connections while a few nodes are highly connected. The mean degree is 2.45, and the median is 1.00, showing that more than half the nodes have only one connection. Most nodes (75 percent) have two or fewer connections, and 90 percent have five or fewer. This distribution is typical of many real-world networks, where a small number of hubs have many connections, and most nodes have few.\n",
        "\n",
        "Since both node and relationship descriptions are not mandatory properties, we will also examine how many were extracted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhOk0M-6a-a0",
        "outputId": "2930d9fa-fc7e-4276-c821-f2e3e2a9d70d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'node', 'total_count': 40, 'non_null_descriptions': 20},\n",
              " {'type': 'relationship', 'total_count': 5, 'non_null_descriptions': 0}]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph.query(\"\"\"\n",
        "MATCH (n:`__Entity__`)\n",
        "RETURN \"node\" AS type,\n",
        "       count(*) AS total_count,\n",
        "       count(n.description) AS non_null_descriptions\n",
        "UNION ALL\n",
        "MATCH (n)-[r:!MENTIONS]->()\n",
        "RETURN \"relationship\" AS type,\n",
        "       count(*) AS total_count,\n",
        "       count(r.description) AS non_null_descriptions\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVphl4p5jIZN"
      },
      "source": [
        "The results show that 5,926 nodes out of 12,994 (45.6 percent) have the description property. On the other hand, only 5,569 relationships out of 15,921 (35 percent) have such a property.\n",
        "\n",
        "Note that due to the probabilistic nature of LLMs, the numbers can vary on different runs and different source data, LLMs, and prompts.\n",
        "\n",
        "### Entity Resolution\n",
        "Entity resolution (de-duplication) is crucial when constructing knowledge graphs because it ensures that each entity is uniquely and accurately represented, preventing duplicates and merging records that refer to the same real-world entity. This process is essential for maintaining data integrity and consistency within the graph. Without entity resolution, knowledge graphs would suffer from fragmented and inconsistent data, leading to errors and unreliable insights.\n",
        "\n",
        "![title](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rlWiW1sWlixDTaY0.png)\n",
        "\n",
        "This image demonstrates how a single real-world entity might appear under slightly different names in different documents and, consequently, in our graph.\n",
        "\n",
        "Moreover, sparse data becomes a significant issue without entity resolution. Incomplete or partial data from various sources can result in scattered and disconnected pieces of information, making it difficult to form a coherent and comprehensive understanding of entities. Accurate entity resolution addresses this by consolidating data, filling in gaps, and creating a unified view of each entity.\n",
        "\n",
        "Overall, entity resolution enhances the efficiency of data retrieval and integration, providing a cohesive view of information across different sources. It ultimately enables more effective question-answering based on a reliable and complete knowledge graph.\n",
        "\n",
        "Unfortunately, the authors of the GraphRAG paper did not include any entity resolution code in their repo, although they mention it in their paper. One reason for leaving this code out could be that it is tough to implement a robust and well-performing entity resolution for any given domain. You can implement custom heuristics for different nodes when dealing with pre-defined types of nodes (when they aren’t predefined, they aren’t consistent enough, like company, organization, business, etc.). However, if the node labels or types aren’t known in advance, as in our case, this becomes an even harder problem. Nonetheless, we will implement a version of entity resolution in our project here, combining text embeddings and graph algorithms with word distance and LLMs.\n",
        "\n",
        "![title](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KlLF01Imn7RlyuSWYkwnqw.png)\n",
        "\n",
        "Our process for entity resolution involves the following steps:\n",
        "\n",
        "1. Entities in the graph — Start with all entities within the graph.\n",
        "2. K-nearest graph — Construct a k-nearest neighbor graph, connecting similar entities based on text embeddings.\n",
        "3. Weakly Connected Components — Identify weakly connected components in the k-nearest graph, grouping entities that are likely to be similar. Add a word distance filtering step after these components have been identified.\n",
        "4. LLM evaluation — Use an LLM to evaluate these components and decide whether the entities within each component should be merged, resulting in a final decision on entity resolution (for example, merging ‘Silicon Valley Bank’ and ‘Silicon_Valley_Bank’ while rejecting the merge for different dates like ‘September 16, 2023’ and ‘September 2, 2023’).\n",
        "\n",
        "We begin by calculating text embeddings for the name and description properties of entities. We can use the from_existing_graph method in the Neo4jVector integration in LangChain to achieve this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYkKe0XOWPTw",
        "outputId": "1cfbde44-077e-48f6-8cd8-616d5b5f17a9"
      },
      "outputs": [],
      "source": [
        "# from langchain_community.vectorstores import Neo4jVector\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# vector = Neo4jVector.from_existing_graph(\n",
        "#     OpenAIEmbeddings(),\n",
        "#     node_label='__Entity__',\n",
        "#     text_node_properties=['id', 'description'],\n",
        "#     embedding_node_property='embedding'\n",
        "# )\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
        "\n",
        "embeddings = OllamaEmbeddings(\n",
        "    model=\"mxbai-embed-large\",\n",
        ")\n",
        "\n",
        "vector = Neo4jVector.from_existing_graph(\n",
        "    embeddings,\n",
        "    # search_type=\"hybrid\",\n",
        "    node_label='__Entity__',\n",
        "    text_node_properties=['id', 'description'],\n",
        "    embedding_node_property=\"embedding\"\n",
        ")\n",
        "\n",
        "# vector_retriever = vector_index.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wvxowyhgk5J"
      },
      "source": [
        "We can use these embeddings to find potential candidates that are similar based on the cosine distance of these embeddings. We will use graph algorithms available in the Graph Data Science (GDS) library; therefore, we can use the GDS Python client for ease of use in a Pythonic way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L4VqsAmYspT",
        "outputId": "aa36fab4-3047-4c4e-9de8-e2588852d200"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from graphdatascience import GraphDataScience\n",
        "# https://neo4j.com/docs/graph-data-science/current/installation/installation-docker/\n",
        "# project graph\n",
        "\n",
        "gds = GraphDataScience(\n",
        "    os.environ[\"NEO4J_URI\"],\n",
        "    auth=(os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGy3e-g6gl-r"
      },
      "source": [
        "If you are not familiar with the GDS library, we first have to project an in-memory graph before we can execute any graph algorithms.\n",
        "\n",
        "![title](https://miro.medium.com/v2/resize:fit:1268/format:webp/1*YdEljYtG2ddd7DrrlzS6yg.png)\n",
        "\n",
        "First, the Neo4j stored graph is projected into an in-memory graph for faster processing and analysis. Next, a graph algorithm is executed on the in-memory graph. Optionally, the algorithm’s results can be stored back into the Neo4j database. Learn more about it in the documentation.\n",
        "\n",
        "To create the k-nearest neighbor graph, we will project all entities along with their text embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3882f5d9054d48cda5b5e2009ad7a9b6",
            "eb7841f10d1948389920a24690ef421b",
            "71885f8fda5246fc8e6c5e3797679158",
            "c285ed227c16418ba6a0c48b353d72ee",
            "8316bd062e1f45118452ee31be1dc195",
            "3d221ca56d12435abfc8f0468f143e7d",
            "388614f2882a449fb87e9453b2a7f527",
            "06b5fd0836ec4f48ba62e44b2717279b",
            "fc56e53314f34d18a38afd8cb29fafb4",
            "8502377116284921bc42589b482d38d9",
            "49dde26b14ac4aa2aa54651453009aeb"
          ]
        },
        "id": "nJpLldiUdpsO",
        "outputId": "676529b4-a41c-4581-c0de-4a8275a177c9"
      },
      "outputs": [],
      "source": [
        "G, result = gds.graph.project(\n",
        "    \"entities2\",                   #  Graph name\n",
        "    \"__Entity__\",                 #  Node projection\n",
        "    \"*\",                          #  Relationship projection\n",
        "    nodeProperties=[\"embedding\"]  #  Configuration parameters\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fthtqjo-gw2F"
      },
      "source": [
        "Now that the graph is projected under the entities name, we can execute graph algorithms. We will begin by constructing a k-nearest graph. The two most important parameters influencing how sparse or dense the k-nearest graph will be are similarityCutoff and topK. The topKis the number of neighbors to find for each node, with a minimum value of 1. The similarity cutoff filters out relationships with similarity below this threshold. Here, we will use a default topKof 10 and a relatively high similarity cutoff of 0.95. Using a high similarity cutoff, such as 0.95, ensures that only highly similar pairs are considered matches, minimizing false positives and improving accuracy.\n",
        "\n",
        "![title](https://miro.medium.com/v2/resize:fit:942/format:webp/1*Wt_9Tj9P_FsU7w1IvpO39g.png)\n",
        "\n",
        "Since we want to store the results back to the projected in-memory graph instead of the knowledge graph, we will use the mutate mode of the algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263,
          "referenced_widgets": [
            "df4cec7aa8f144e4bfcbb0dcbf1b1746",
            "70e2c72d9d404f4aa8c2b764e7af7b93",
            "55ecc81af9c44546b8a8140a821003ac",
            "c3da34580c2342d597c65787cb15013e",
            "290b8c08c2b648889c5ac98e59efbb70",
            "d289f0a2b44a4760ad3deb3e52bd529b",
            "37adfa0460674f18b40c32e7d412ad98",
            "aca4392d8f0640d19026ad011e047e42",
            "76562367afe7484ab28e83d450e45785",
            "60ed05fde48d44ac831cd72e5e249b28",
            "47751790b8d94346bf786df2fcaf16b5"
          ]
        },
        "id": "DWdGhMmgeuFL",
        "outputId": "72e71712-08ed-4f42-bcbd-e25be6021392"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ranIterations                                                             3\n",
              "nodePairsConsidered                                                    9907\n",
              "didConverge                                                            True\n",
              "preProcessingMillis                                                       0\n",
              "computeMillis                                                            28\n",
              "mutateMillis                                                              5\n",
              "postProcessingMillis                                                      0\n",
              "nodesCompared                                                            40\n",
              "relationshipsWritten                                                      0\n",
              "similarityDistribution    {'min': 0.0, 'p5': 0.0, 'max': 5.0872912848509...\n",
              "configuration             {'mutateProperty': 'score', 'jobId': '418c1bc5...\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarity_threshold = 0.95\n",
        "\n",
        "gds.knn.mutate(\n",
        "  G,\n",
        "  nodeProperties=['embedding'],\n",
        "  mutateRelationshipType= 'SIMILAR',\n",
        "  mutateProperty= 'score',\n",
        "  similarityCutoff=similarity_threshold\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dg7vZrGg7ZW"
      },
      "source": [
        "The next step is to identify groups of entities that are connected with the newly inferred similarity relationships. Identifying groups of connected nodes is a frequent process in network analysis, often called community detection or clustering, which involves finding subgroups of densely connected nodes. In this example, we will use the Weakly Connected Components algorithm, which helps us find parts of a graph where all nodes are connected, even if we ignore the direction of the connections.\n",
        "\n",
        "![title](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZhawRXqvoZ6EuuUzacCf7A.png)\n",
        "\n",
        "We use the algorithm’s write mode to store the results back to the database (stored graph):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Juc1fFiFf73-",
        "outputId": "c9c76c9c-6a11-47cd-f800-f9e6c1890eff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "writeMillis                                                             50\n",
              "nodePropertiesWritten                                                   40\n",
              "componentCount                                                          40\n",
              "componentDistribution    {'min': 1, 'p5': 1, 'max': 1, 'p999': 1, 'p99'...\n",
              "postProcessingMillis                                                     3\n",
              "preProcessingMillis                                                      0\n",
              "computeMillis                                                            0\n",
              "configuration            {'writeProperty': 'wcc', 'jobId': 'dff26014-73...\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gds.wcc.write(\n",
        "    G,\n",
        "    writeProperty=\"wcc\",\n",
        "    relationshipTypes=[\"SIMILAR\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8euMSB4hElG"
      },
      "source": [
        "Text embedding comparison helps find potential duplicates, but it is only part of the entity resolution process. For example, Google and Apple are very close in the embedding space (0.96 cosine similarity using the ada-002 embedding model). The same goes for BMW and Mercedes Benz (0.97 cosine similarity). High text embedding similarity is a good start, but we can improve it. Therefore, we will add an additional filter allowing only pairs of words with a text distance of three or fewer (meaning that only the characters can be changed):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2mjWpcagO-h",
        "outputId": "9016a6b2-1497-4ae8-c461-f933c0533e41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_edit_distance = 3\n",
        "potential_duplicate_candidates = graph.query(\n",
        "    \"\"\"MATCH (e:`__Entity__`)\n",
        "    WHERE size(e.id) > 4 // longer than 4 characters\n",
        "    WITH e.wcc AS community, collect(e) AS nodes, count(*) AS count\n",
        "    WHERE count > 1\n",
        "    UNWIND nodes AS node\n",
        "    // Add text distance\n",
        "    WITH distinct\n",
        "      [n IN nodes WHERE apoc.text.distance(toLower(node.id), toLower(n.id)) < $distance | n.id] AS intermediate_results\n",
        "    WHERE size(intermediate_results) > 1\n",
        "    WITH collect(intermediate_results) AS results\n",
        "    // combine groups together if they share elements\n",
        "    UNWIND range(0, size(results)-1, 1) as index\n",
        "    WITH results, index, results[index] as result\n",
        "    WITH apoc.coll.sort(reduce(acc = result, index2 IN range(0, size(results)-1, 1) |\n",
        "            CASE WHEN index <> index2 AND\n",
        "                size(apoc.coll.intersection(acc, results[index2])) > 0\n",
        "                THEN apoc.coll.union(acc, results[index2])\n",
        "                ELSE acc\n",
        "            END\n",
        "    )) as combinedResult\n",
        "    WITH distinct(combinedResult) as combinedResult\n",
        "    // extra filtering\n",
        "    WITH collect(combinedResult) as allCombinedResults\n",
        "    UNWIND range(0, size(allCombinedResults)-1, 1) as combinedResultIndex\n",
        "    WITH allCombinedResults[combinedResultIndex] as combinedResult, combinedResultIndex, allCombinedResults\n",
        "    WHERE NOT any(x IN range(0,size(allCombinedResults)-1,1)\n",
        "        WHERE x <> combinedResultIndex\n",
        "        AND apoc.coll.containsAll(allCombinedResults[x], combinedResult)\n",
        "    )\n",
        "    RETURN combinedResult\n",
        "    \"\"\", params={'distance': word_edit_distance})\n",
        "potential_duplicate_candidates[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X-UwzLqhJT9"
      },
      "source": [
        "This Cypher statement is slightly more involved, and its interpretation is beyond the scope of this blog post. You can always ask an LLM to interpret it.\n",
        "\n",
        "Additionally, the word distance cutoff could be a function of the length of the word instead of a single number and the implementation could be more scalable.\n",
        "\n",
        "What is important is that it outputs groups of potential entities we might want to merge.\n",
        "\n",
        "As you can see, our resolution approach works better for some node types than others. Based on a quick examination, it seems to work better for people and organizations, while it’s pretty bad for dates. If we used predefined node types, we could prepare different heuristics for various node types. In this example, we do not have predefined node labels, so we will turn to an LLM to make the final decision about whether entities should be merged or not.\n",
        "\n",
        "First, we need to formulate the LLM prompt to effectively guide and inform the final decision regarding the merging of the nodes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "ABQOLHRshVU_"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"You are a data processing assistant. Your task is to identify duplicate entities in a list and decide which of them should be merged.\n",
        "The entities might be slightly different in format or content, but essentially refer to the same thing. Use your analytical skills to determine duplicates.\n",
        "\n",
        "Here are the rules for identifying duplicates:\n",
        "1. Entities with minor typographical differences should be considered duplicates.\n",
        "2. Entities with different formats but the same content should be considered duplicates.\n",
        "3. Entities that refer to the same real-world object or concept, even if described differently, should be considered duplicates.\n",
        "4. If it refers to different numbers, dates, or products, do not merge results\n",
        "\"\"\"\n",
        "user_template = \"\"\"\n",
        "Here is the list of entities to process:\n",
        "{entities}\n",
        "\n",
        "Please identify duplicates, merge them, and provide the merged list.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CbHzuTohXzw"
      },
      "source": [
        "I always like to use with_structured_output method in LangChain when expecting structured data output to avoid having to parse the outputs manually.\n",
        "\n",
        "Here, we will define the output as a list of lists, where each inner list contains the entities that should be merged. This structure is used to handle scenarios where, for example, the input might be [Sony, Sony Inc, Google, Google Inc]. In such cases, you would want to merge “Sony” and “Sony Inc” separately from “Google” and “Google Inc.”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "f3uaBpUEF3EF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from retry import retry\n",
        "\n",
        "class DuplicateEntities(BaseModel):\n",
        "    entities: List[str] = Field(\n",
        "        description=\"Entities that represent the same object or real-world entity and should be merged\"\n",
        "    )\n",
        "\n",
        "\n",
        "class Disambiguate(BaseModel):\n",
        "    merge_entities: Optional[List[DuplicateEntities]] = Field(\n",
        "        description=\"Lists of entities that represent the same object or real-world entity and should be merged\"\n",
        "    )\n",
        "\n",
        "\n",
        "extraction_llm = OllamaFunctions(model=llm_model).with_structured_output(\n",
        "    Disambiguate\n",
        ")\n",
        "\n",
        "extraction_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            system_prompt,\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            user_template,\n",
        "        ),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWFkbPsthcTY"
      },
      "source": [
        "Next, we integrate the LLM prompt with the structured output to create a chain using LangChain Expression Language (LCEL) syntax and encapsulate it within a disambiguate function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "rRyqLAHShguX"
      },
      "outputs": [],
      "source": [
        "extraction_chain = extraction_prompt | extraction_llm\n",
        "\n",
        "@retry(tries=3, delay=2)\n",
        "def entity_resolution(entities: List[str]) -> Optional[List[str]]:\n",
        "    return [\n",
        "        el.entities\n",
        "        for el in extraction_chain.invoke({\"entities\": entities}).merge_entities\n",
        "    ]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPMwVQjIJQAg",
        "outputId": "3699ec52-9add-496e-c099-dde5f922e596"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "type object 'Disambiguate' has no attribute 'model_construct'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mentity_resolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStar Ocean The Second Story R\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStar Ocean: The Second Story R\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\retry\\api.py:73\u001b[0m, in \u001b[0;36mretry.<locals>.retry_decorator\u001b[1;34m(f, *fargs, **fkwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m args \u001b[38;5;241m=\u001b[39m fargs \u001b[38;5;28;01mif\u001b[39;00m fargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     72\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m fkwargs \u001b[38;5;28;01mif\u001b[39;00m fkwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__retry_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexceptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\retry\\api.py:33\u001b[0m, in \u001b[0;36m__retry_internal\u001b[1;34m(f, exceptions, tries, delay, max_delay, backoff, jitter, logger)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m _tries:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     35\u001b[0m         _tries \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "Cell \u001b[1;32mIn[99], line 7\u001b[0m, in \u001b[0;36mentity_resolution\u001b[1;34m(entities)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;129m@retry\u001b[39m(tries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, delay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentity_resolution\u001b[39m(entities: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[List[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m      6\u001b[0m         el\u001b[38;5;241m.\u001b[39mentities\n\u001b[1;32m----> 7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[43mextraction_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mentities\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmerge_entities\n\u001b[0;32m      8\u001b[0m     ]\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_experimental\\llms\\ollama_functions.py:305\u001b[0m, in \u001b[0;36mOllamaFunctions._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `function_call` is specified, you must also pass a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching function in `functions`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         )\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 305\u001b[0m functions \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mconvert_to_ollama_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    306\u001b[0m functions\u001b[38;5;241m.\u001b[39mappend(DEFAULT_RESPONSE_FUNCTION)\n\u001b[0;32m    307\u001b[0m system_message_prompt_template \u001b[38;5;241m=\u001b[39m SystemMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtool_system_prompt_template\n\u001b[0;32m    309\u001b[0m )\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_experimental\\llms\\ollama_functions.py:305\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `function_call` is specified, you must also pass a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching function in `functions`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         )\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 305\u001b[0m functions \u001b[38;5;241m=\u001b[39m [\u001b[43mconvert_to_ollama_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m functions]\n\u001b[0;32m    306\u001b[0m functions\u001b[38;5;241m.\u001b[39mappend(DEFAULT_RESPONSE_FUNCTION)\n\u001b[0;32m    307\u001b[0m system_message_prompt_template \u001b[38;5;241m=\u001b[39m SystemMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtool_system_prompt_template\n\u001b[0;32m    309\u001b[0m )\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_experimental\\llms\\ollama_functions.py:86\u001b[0m, in \u001b[0;36mconvert_to_ollama_tool\u001b[1;34m(tool)\u001b[0m\n\u001b[0;32m     84\u001b[0m description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pydantic_class(tool):\n\u001b[1;32m---> 86\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_construct\u001b[49m()\u001b[38;5;241m.\u001b[39mmodel_json_schema()\n\u001b[0;32m     87\u001b[0m     name \u001b[38;5;241m=\u001b[39m schema[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool, BaseTool):\n",
            "\u001b[1;31mAttributeError\u001b[0m: type object 'Disambiguate' has no attribute 'model_construct'"
          ]
        }
      ],
      "source": [
        "entity_resolution(['Star Ocean The Second Story R', 'Star Ocean: The Second Story R'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3gNrAoUJdKA",
        "outputId": "c8063c6b-975f-460e-c2e0-83e90b9b5eed"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "type object 'Disambiguate' has no attribute 'model_construct'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mentity_resolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDecember 16, 2023\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDecember 2, 2023\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDecember 23, 2023\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDecember 26, 2023\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDecember 30, 2023\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDecember 5, 2023\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDecember 9, 2023\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\retry\\api.py:73\u001b[0m, in \u001b[0;36mretry.<locals>.retry_decorator\u001b[1;34m(f, *fargs, **fkwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m args \u001b[38;5;241m=\u001b[39m fargs \u001b[38;5;28;01mif\u001b[39;00m fargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     72\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m fkwargs \u001b[38;5;28;01mif\u001b[39;00m fkwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__retry_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexceptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\retry\\api.py:33\u001b[0m, in \u001b[0;36m__retry_internal\u001b[1;34m(f, exceptions, tries, delay, max_delay, backoff, jitter, logger)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m _tries:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     35\u001b[0m         _tries \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "Cell \u001b[1;32mIn[20], line 7\u001b[0m, in \u001b[0;36mentity_resolution\u001b[1;34m(entities)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;129m@retry\u001b[39m(tries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, delay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentity_resolution\u001b[39m(entities: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[List[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m      6\u001b[0m         el\u001b[38;5;241m.\u001b[39mentities\n\u001b[1;32m----> 7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[43mextraction_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mentities\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmerge_entities\n\u001b[0;32m      8\u001b[0m     ]\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\ollama_functions.py:305\u001b[0m, in \u001b[0;36mOllamaFunctions._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `function_call` is specified, you must also pass a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching function in `functions`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         )\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 305\u001b[0m functions \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mconvert_to_ollama_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    306\u001b[0m functions\u001b[38;5;241m.\u001b[39mappend(DEFAULT_RESPONSE_FUNCTION)\n\u001b[0;32m    307\u001b[0m system_message_prompt_template \u001b[38;5;241m=\u001b[39m SystemMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtool_system_prompt_template\n\u001b[0;32m    309\u001b[0m )\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\ollama_functions.py:305\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `function_call` is specified, you must also pass a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching function in `functions`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         )\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 305\u001b[0m functions \u001b[38;5;241m=\u001b[39m [\u001b[43mconvert_to_ollama_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m functions]\n\u001b[0;32m    306\u001b[0m functions\u001b[38;5;241m.\u001b[39mappend(DEFAULT_RESPONSE_FUNCTION)\n\u001b[0;32m    307\u001b[0m system_message_prompt_template \u001b[38;5;241m=\u001b[39m SystemMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtool_system_prompt_template\n\u001b[0;32m    309\u001b[0m )\n",
            "File \u001b[1;32md:\\James\\Py_repos\\GraphRAG-with-Llama-3.1\\ollama_functions.py:86\u001b[0m, in \u001b[0;36mconvert_to_ollama_tool\u001b[1;34m(tool)\u001b[0m\n\u001b[0;32m     84\u001b[0m description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pydantic_class(tool):\n\u001b[1;32m---> 86\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_construct\u001b[49m()\u001b[38;5;241m.\u001b[39mmodel_json_schema()\n\u001b[0;32m     87\u001b[0m     name \u001b[38;5;241m=\u001b[39m schema[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool, BaseTool):\n",
            "\u001b[1;31mAttributeError\u001b[0m: type object 'Disambiguate' has no attribute 'model_construct'"
          ]
        }
      ],
      "source": [
        "entity_resolution({\"entities\": ['December 16, 2023',\n",
        "   'December 2, 2023',\n",
        "   'December 23, 2023',\n",
        "   'December 26, 2023',\n",
        "   'December 30, 2023',\n",
        "   'December 5, 2023',\n",
        "   'December 9, 2023']})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL0WhRpChpDP"
      },
      "source": [
        "We need to run all potential candidate nodes through the entity_resolution function to decide whether they should be merged. To speed up the process, we will again parallelize the LLM calls:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofXSUcm8KSrI",
        "outputId": "74c0987c-0332-46c6-f8c4-6ca425349c41"
      },
      "outputs": [],
      "source": [
        "merged_entities = []\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "    # Submitting all tasks and creating a list of future objects\n",
        "    futures = [\n",
        "        executor.submit(entity_resolution, el['combinedResult'])\n",
        "        for el in potential_duplicate_candidates\n",
        "    ]\n",
        "\n",
        "    for future in tqdm(\n",
        "        as_completed(futures), total=len(futures), desc=\"Processing documents\"\n",
        "    ):\n",
        "        to_merge = future.result()\n",
        "        if to_merge:\n",
        "            merged_entities.extend(to_merge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmuqZmrGLmSp",
        "outputId": "382783c2-7fe0-4f69-e09c-1f4fd14a1c5a"
      },
      "outputs": [],
      "source": [
        "merged_entities[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peZElkVJhuaP"
      },
      "source": [
        "The final step of entity resolution involves taking the results from the entity_resolution LLM and writing them back to the database by merging the specified nodes:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8Mg310yMLhZ",
        "outputId": "f1ca21a8-874d-4f5c-b1bd-d5db5b8bf26a"
      },
      "outputs": [],
      "source": [
        "graph.query(\"\"\"\n",
        "UNWIND $data AS candidates\n",
        "CALL {\n",
        "  WITH candidates\n",
        "  MATCH (e:__Entity__) WHERE e.id IN candidates\n",
        "  RETURN collect(e) AS nodes\n",
        "}\n",
        "CALL apoc.refactor.mergeNodes(nodes, {properties: {\n",
        "    `.*`: 'discard'\n",
        "}})\n",
        "YIELD node\n",
        "RETURN count(*)\n",
        "\"\"\", params={\"data\": merged_entities})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgGHDn-Wi1BH",
        "outputId": "3ae9a773-4f3d-491f-9743-28b2b7916457"
      },
      "outputs": [],
      "source": [
        "G.drop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nwk7OgPjVPK"
      },
      "source": [
        "This entity resolution is not perfect, but it gives us a starting point upon which we can improve. Additionally, we can improve the logic for determining which entities should be retained.\n",
        "\n",
        "### Element Summarization\n",
        "In the next step, the authors perform an element summarization step. Essentially, every node and relationship gets passed through an entity summarization prompt. The authors note the novelty and interest of their approach:\n",
        "\n",
        "“Overall, our use of rich descriptive text for homogeneous nodes in a potentially noisy graph structure is aligned with both the capabilities of LLMs and the needs of global, query-focused summarization. These qualities also differentiate our graph index from typical knowledge graphs, which rely on concise and consistent knowledge triples (subject, predicate, object) for downstream reasoning tasks.”\n",
        "\n",
        "The idea is exciting. We still extract subject and object IDs or names from text, which allows us to link relationships to correct entities, even when entities appear across multiple text chunks. However, the relationships aren’t reduced to a single type. Instead, the relationship type is actually a freeform text that allows us to retain richer and more nuanced information.\n",
        "\n",
        "Additionally, the entity information is summarized using an LLM, allowing us to embed and index this information and entities more efficiently for more accurate retrieval.\n",
        "\n",
        "One could argue that this richer and more nuanced information could also be retained by adding additional, possibly arbitrary, node and relationship properties. One issue with arbitrary node and relationship properties is that it could be hard to extract the information consistently because the LLM might use different property names or focus on various details on every execution.\n",
        "\n",
        "Some of these problems could be solved using predefined property names with additional type and description information. In that case, you would need a subject-matter expert to help define those properties, leaving little room for an LLM to extract any vital information outside the predefined descriptions.\n",
        "\n",
        "It’s an exciting approach to represent richer information in a knowledge graph.\n",
        "\n",
        "One potential issue with the element summarization step is that it does not scale well since it requires an LLM call for every entity and relationship in the graph. Our graph is relatively tiny with 13,000 nodes and 16,000 relationships. Even for such a small graph, we would require 29,000 LLM calls, and each call would use a couple hundred tokens, making it quite expensive and time-intensive. Therefore, we will avoid this step here. We can still use the description properties extracted during the initial text processing.\n",
        "\n",
        "### Constructing and Summarizing Communities\n",
        "The final step in the graph construction and indexing process involves identifying communities within the graph. In this context, a community is a group of nodes that are more densely connected to each other than to the rest of the graph, indicating a higher level of interaction or similarity. The following visualization shows an example of community detection results.\n",
        "\n",
        "![title](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*l2i3ctl8s6xdR6ul.png)\n",
        "\n",
        "Once these entity communities are identified with a clustering algorithm, an LLM generates a summary for each community, providing insights into their individual characteristics and relationships.\n",
        "\n",
        "Again, we use the Graph Data Science library. We start by projecting an in-memory graph. To follow the original article precisely, we will project the graph of entities as an undirected weighted network, where the network represents the number of connections between two entities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VCZpBBMjGQq"
      },
      "outputs": [],
      "source": [
        "G, result = gds.graph.project(\n",
        "    \"communities\",  #  Graph name\n",
        "    \"__Entity__\",  #  Node projection\n",
        "    {\n",
        "        \"_ALL_\": {\n",
        "            \"type\": \"*\",\n",
        "            \"orientation\": \"UNDIRECTED\",\n",
        "            \"properties\": {\"weight\": {\"property\": \"*\", \"aggregation\": \"COUNT\"}},\n",
        "        }\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tuPpCJ3iAZZ"
      },
      "source": [
        "The authors employed the Leiden algorithm, a hierarchical clustering method, to identify communities within the graph. One advantage of using a hierarchical community detection algorithm is the ability to examine communities at multiple levels of granularity. The authors suggest summarizing all communities at each level, providing a comprehensive understanding of the graph’s structure.\n",
        "\n",
        "First, we will use the Weakly Connected Components (WCC) algorithm to assess the connectivity of our graph. This algorithm identifies isolated sections within the graph, meaning it detects subsets of nodes or components that are connected to each other but not to the rest of the graph. These components help us understand the fragmentation within the network and identify groups of nodes that are independent from others. WCC is vital for analyzing the overall structure and connectivity of the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs-nCOuWuW6M",
        "outputId": "2b89168c-e0de-4d43-9bae-0defb66a6177"
      },
      "outputs": [],
      "source": [
        "wcc = gds.wcc.stats(G)\n",
        "print(f\"Component count: {wcc['componentCount']}\")\n",
        "print(f\"Component distribution: {wcc['componentDistribution']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbQkCrH8iCPY"
      },
      "source": [
        "The WCC algorithm results identified 1,119 distinct components. Notably, the largest component comprises 9,109 nodes, common in real-world networks where a single super component coexists with numerous smaller isolated components. The smallest component has one node, and the average component size is about 11.3 nodes.\n",
        "\n",
        "Next, we will run the Leiden algorithm, which is also available in the GDS library, and enable the includeIntermediateCommunities parameter to return and store communities at all levels. We have also included a relationshipWeightProperty parameter to run the weighted variant of the Leiden algorithm. Using the write mode of the algorithm stores the results as a node property."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9aLrUsykFa0",
        "outputId": "3163d266-eb0a-4280-c0fe-3541b085fe79"
      },
      "outputs": [],
      "source": [
        "gds.leiden.write(\n",
        "    G,\n",
        "    writeProperty=\"communities\",\n",
        "    includeIntermediateCommunities=True,\n",
        "    relationshipWeightProperty=\"weight\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a5AxvzLiHHa"
      },
      "source": [
        "The algorithm identified five levels of communities, with the highest (least granular level where communities are largest) having 1,188 communities (as opposed to 1,119 components). Building on this, we will create a distinct node for each community and represent their hierarchical structure as an interconnected graph. Later, we will also store community summaries and other attributes as node properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qIC9PZcGujw",
        "outputId": "ca868bb4-363d-43bc-a6cf-c782bf31b70e"
      },
      "outputs": [],
      "source": [
        "graph.query(\"CREATE CONSTRAINT IF NOT EXISTS FOR (c:__Community__) REQUIRE c.id IS UNIQUE;\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKRaBUjpwNNs",
        "outputId": "411bac03-6a28-4f65-f775-18b185834e06"
      },
      "outputs": [],
      "source": [
        "graph.query(\"\"\"\n",
        "MATCH (e:`__Entity__`)\n",
        "UNWIND range(0, size(e.communities) - 1 , 1) AS index\n",
        "CALL {\n",
        "  WITH e, index\n",
        "  WITH e, index\n",
        "  WHERE index = 0\n",
        "  MERGE (c:`__Community__` {id: toString(index) + '-' + toString(e.communities[index])})\n",
        "  ON CREATE SET c.level = index\n",
        "  MERGE (e)-[:IN_COMMUNITY]->(c)\n",
        "  RETURN count(*) AS count_0\n",
        "}\n",
        "CALL {\n",
        "  WITH e, index\n",
        "  WITH e, index\n",
        "  WHERE index > 0\n",
        "  MERGE (current:`__Community__` {id: toString(index) + '-' + toString(e.communities[index])})\n",
        "  ON CREATE SET current.level = index\n",
        "  MERGE (previous:`__Community__` {id: toString(index - 1) + '-' + toString(e.communities[index - 1])})\n",
        "  ON CREATE SET previous.level = index - 1\n",
        "  MERGE (previous)-[:IN_COMMUNITY]->(current)\n",
        "  RETURN count(*) AS count_1\n",
        "}\n",
        "RETURN count(*)\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoIno_V3iOOZ"
      },
      "source": [
        "The authors also introduce a community rank, indicating the number of distinct text chunks in which the entities within the community appear:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA4CZxcyIkd8",
        "outputId": "a61e223e-79ad-430d-9dbc-4a30b180facd"
      },
      "outputs": [],
      "source": [
        "graph.query(\"\"\"\n",
        "MATCH (c:__Community__)<-[:IN_COMMUNITY*]-(:__Entity__)<-[:MENTIONS]-(d:Document)\n",
        "WITH c, count(distinct d) AS rank\n",
        "SET c.community_rank = rank;\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6V00ZDKiQ-w"
      },
      "source": [
        "Now let’s examine a sample hierarchical structure with many intermediate communities merging at higher levels. The communities are non-overlapping, meaning that each entity belongs to precisely a single community at each level.\n",
        "Let’s examine the number of communities and their sizes and different levels in more detail:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sU2Eg54TLjAV",
        "outputId": "1d6a6ffd-8256-4aa6-b2f1-c275f1218621"
      },
      "outputs": [],
      "source": [
        "community_size = graph.query(\n",
        "    \"\"\"\n",
        "MATCH (c:__Community__)<-[:IN_COMMUNITY*]-(e:__Entity__)\n",
        "WITH c, count(distinct e) AS entities\n",
        "RETURN split(c.id, '-')[0] AS level, entities\n",
        "\"\"\"\n",
        ")\n",
        "community_size_df = pd.DataFrame.from_records(community_size)\n",
        "percentiles_data = []\n",
        "for level in community_size_df[\"level\"].unique():\n",
        "    subset = community_size_df[community_size_df[\"level\"] == level][\"entities\"]\n",
        "    num_communities = len(subset)\n",
        "    percentiles = np.percentile(subset, [25, 50, 75, 90, 99])\n",
        "    percentiles_data.append(\n",
        "        [\n",
        "            level,\n",
        "            num_communities,\n",
        "            percentiles[0],\n",
        "            percentiles[1],\n",
        "            percentiles[2],\n",
        "            percentiles[3],\n",
        "            percentiles[4],\n",
        "            max(subset)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# Create a DataFrame with the percentiles\n",
        "percentiles_df = pd.DataFrame(\n",
        "    percentiles_data,\n",
        "    columns=[\n",
        "        \"Level\",\n",
        "        \"Number of communities\",\n",
        "        \"25th Percentile\",\n",
        "        \"50th Percentile\",\n",
        "        \"75th Percentile\",\n",
        "        \"90th Percentile\",\n",
        "        \"99th Percentile\",\n",
        "        \"Max\"\n",
        "    ],\n",
        ")\n",
        "percentiles_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLE47rf9iYIh"
      },
      "source": [
        "In the original implementation, communities on every level were summarized. In our case, that would be 8,590 communities and, consequently, 8,590 LLM calls. I would argue that depending on the hierarchical community structure, not every level needs to be summarized. For example, the difference between the last and the next-to-last level is only four communities (1,192 vs. 1,188). Therefore, we would be creating a lot of redundant summaries. One solution is to create an implementation that can make a single summary for communities on different levels that don’t change; another one would be to collapse community hierarchies that don’t change.\n",
        "\n",
        "Also, I am unsure if we want to summarize communities with only one member, as they might not provide much value or information. Here, we will summarize communities on levels 0, 1, and 4. First, we need to retrieve their information from the database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4NuLhY0mm3B"
      },
      "outputs": [],
      "source": [
        "community_info = graph.query(\"\"\"\n",
        "MATCH (c:`__Community__`)<-[:IN_COMMUNITY*]-(e:__Entity__)\n",
        "WHERE c.level IN [0,1,4]\n",
        "WITH c, collect(e ) AS nodes\n",
        "WHERE size(nodes) > 1\n",
        "CALL apoc.path.subgraphAll(nodes[0], {\n",
        "\twhitelistNodes:nodes\n",
        "})\n",
        "YIELD relationships\n",
        "RETURN c.id AS communityId,\n",
        "       [n in nodes | {id: n.id, description: n.description, type: [el in labels(n) WHERE el <> '__Entity__'][0]}] AS nodes,\n",
        "       [r in relationships | {start: startNode(r).id, type: type(r), end: endNode(r).id, description: r.description}] AS rels\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur4JkHkLe3_i",
        "outputId": "90445e3d-b3bc-4d54-d9b4-b96e8a568657"
      },
      "outputs": [],
      "source": [
        "community_info[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_ybgPpwieQk"
      },
      "source": [
        "Now, we need to prepare an LLM prompt that generates a natural language summarization based on the information provided by the elements of our community. We can take some inspiration from the [prompt the researchers used](https://github.com/microsoft/graphrag/blob/main/graphrag/prompt_tune/template/community_report_summarization.py).\n",
        "\n",
        "The authors not only summarized communities but also generated findings for each of them. A finding can be defined as concise information regarding a specific event or piece of information. One such example:\n",
        "```\n",
        "\"summary\": \"Abila City Park as the central location\",\n",
        "\"explanation\": \"Abila City Park is the central entity in this community, serving as the location for the POK rally. This park is the common link between all other\n",
        "entities, suggesting its significance in the community. The park's association with the rally could potentially lead to issues such as public disorder or conflict, depending on the\n",
        "nature of the rally and the reactions it provokes. [records: Entities (5), Relationships (37, 38, 39, 40)]\"\n",
        "```\n",
        "My intuition suggests that extracting findings with just a single pass might not be as comprehensive as we need, much like extracting entities and relationships.\n",
        "\n",
        "Furthermore, I have not found any references or examples of their use in their code in either local or global search retrievers. As a result, we’ll refrain from extracting findings in this instance. Or, as academics often put it: This exercise is left to the reader. Additionally, we have also skipped the claims or covariate information extraction, which looks similar to findings at first glance.\n",
        "\n",
        "The prompt we’ll use to produce the community summaries is fairly straightforward:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tnc8aqN_e5M7"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "community_template = \"\"\"Based on the provided nodes and relationships that belong to the same graph community,\n",
        "generate a natural language summary of the provided information:\n",
        "{community_info}\n",
        "\n",
        "Summary:\"\"\"  # noqa: E501\n",
        "\n",
        "community_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Given an input triples, generate the information summary. No pre-amble.\",\n",
        "        ),\n",
        "        (\"human\", community_template),\n",
        "    ]\n",
        ")\n",
        "\n",
        "community_chain = community_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6PdeC7WisWp"
      },
      "source": [
        "The only thing left is to turn community representations into strings to reduce the number of tokens by avoiding JSON token overhead and wrap the chain as a function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdcKulkxVsXc"
      },
      "outputs": [],
      "source": [
        "def prepare_string(data):\n",
        "    nodes_str = \"Nodes are:\\n\"\n",
        "    for node in data['nodes']:\n",
        "        node_id = node['id']\n",
        "        node_type = node['type']\n",
        "        if 'description' in node and node['description']:\n",
        "            node_description = f\", description: {node['description']}\"\n",
        "        else:\n",
        "            node_description = \"\"\n",
        "        nodes_str += f\"id: {node_id}, type: {node_type}{node_description}\\n\"\n",
        "\n",
        "    rels_str = \"Relationships are:\\n\"\n",
        "    for rel in data['rels']:\n",
        "        start = rel['start']\n",
        "        end = rel['end']\n",
        "        rel_type = rel['type']\n",
        "        if 'description' in rel and rel['description']:\n",
        "            description = f\", description: {rel['description']}\"\n",
        "        else:\n",
        "            description = \"\"\n",
        "        rels_str += f\"({start})-[:{rel_type}]->({end}){description}\\n\"\n",
        "\n",
        "    return nodes_str + \"\\n\" + rels_str\n",
        "\n",
        "def process_community(community):\n",
        "    stringify_info = prepare_string(community)\n",
        "    summary = community_chain.invoke({'community_info': stringify_info})\n",
        "    return {\"community\": community['communityId'], \"summary\": summary}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4RC8ydEWB0N",
        "outputId": "aa698b81-98d6-4c63-af9f-dddde30a4e83"
      },
      "outputs": [],
      "source": [
        "print(prepare_string(community_info[3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNnO_edyiwa0"
      },
      "source": [
        "Now we can generate community summaries for the selected levels. Again, we parallelize calls for faster execution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IERhJ3jgWtk",
        "outputId": "ec085ca8-8e1a-4445-8e57-5018105941e2"
      },
      "outputs": [],
      "source": [
        "summaries = []\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    futures = {executor.submit(process_community, community): community for community in community_info}\n",
        "\n",
        "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing communities\"):\n",
        "        summaries.append(future.result())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk2DEFEFi2ry"
      },
      "source": [
        "One aspect I didn’t mention is that the authors also address the potential issue of exceeding context size when inputting community information. As graphs expand, the communities can grow significantly as well. In our case, the largest community comprised 545 members. Given that GPT-4o has a context size exceeding 100,000 tokens, we decided to skip this step.\n",
        "\n",
        "As our final step, we will store the community summaries back to the database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKymAMJehSkw",
        "outputId": "857a4cee-1222-499c-9842-6e01a0e592e0"
      },
      "outputs": [],
      "source": [
        "# Store summaries\n",
        "graph.query(\"\"\"\n",
        "UNWIND $data AS row\n",
        "MERGE (c:__Community__ {id:row.community})\n",
        "SET c.summary = row.summary\n",
        "\"\"\", params={\"data\": summaries})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLX6Wrqai-sD"
      },
      "source": [
        "The final graph structure:\n",
        "\n",
        "![title](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rkgiVH20AuG1X-rMzTipXQ.png)\n",
        "\n",
        "The graph now contains the original documents, extracted entities and relationships, as well as hierarchical community structure and summaries.\n",
        "\n",
        "Summary\n",
        "The authors of the “From Local to Global” paper have done a great job in demonstrating a new approach to GraphRAG. They show how we can combine and summarize information from various documents into a hierarchical knowledge graph structure.\n",
        "\n",
        "One thing that isn’t explicitly mentioned is that we can also integrate structured data sources in a graph; the input doesn’t have to be limited to unstructured text only.\n",
        "\n",
        "What I particularly appreciate about their extraction approach is that they capture descriptions for both nodes and relationships. Descriptions allow the LLM to retain more information than reducing everything to just node IDs and relationship types.\n",
        "\n",
        "Additionally, they demonstrate that a single extraction pass over the text might not capture all relevant information and introduce logic to perform multiple passes if necessary. The authors also present an interesting idea for performing summarizations over graph communities, allowing us to embed and index condensed topical information across multiple data sources.\n",
        "\n",
        "In the next blog post, we will go over the local and global search retriever implementations and talk about other approaches we could implement based on the given graph structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y30zWS6FXya6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcPPm1tJi9c6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOgOLIEBDxiSBtGn1xLBXHD",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06b5fd0836ec4f48ba62e44b2717279b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "290b8c08c2b648889c5ac98e59efbb70": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37adfa0460674f18b40c32e7d412ad98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3882f5d9054d48cda5b5e2009ad7a9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb7841f10d1948389920a24690ef421b",
              "IPY_MODEL_71885f8fda5246fc8e6c5e3797679158",
              "IPY_MODEL_c285ed227c16418ba6a0c48b353d72ee"
            ],
            "layout": "IPY_MODEL_8316bd062e1f45118452ee31be1dc195"
          }
        },
        "388614f2882a449fb87e9453b2a7f527": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d221ca56d12435abfc8f0468f143e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47751790b8d94346bf786df2fcaf16b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49dde26b14ac4aa2aa54651453009aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55ecc81af9c44546b8a8140a821003ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aca4392d8f0640d19026ad011e047e42",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76562367afe7484ab28e83d450e45785",
            "value": 100
          }
        },
        "60ed05fde48d44ac831cd72e5e249b28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70e2c72d9d404f4aa8c2b764e7af7b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d289f0a2b44a4760ad3deb3e52bd529b",
            "placeholder": "​",
            "style": "IPY_MODEL_37adfa0460674f18b40c32e7d412ad98",
            "value": "Knn: 100%"
          }
        },
        "71885f8fda5246fc8e6c5e3797679158": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06b5fd0836ec4f48ba62e44b2717279b",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc56e53314f34d18a38afd8cb29fafb4",
            "value": 100
          }
        },
        "76562367afe7484ab28e83d450e45785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8316bd062e1f45118452ee31be1dc195": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8502377116284921bc42589b482d38d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aca4392d8f0640d19026ad011e047e42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c285ed227c16418ba6a0c48b353d72ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8502377116284921bc42589b482d38d9",
            "placeholder": "​",
            "style": "IPY_MODEL_49dde26b14ac4aa2aa54651453009aeb",
            "value": " 100.0/100 [00:23&lt;00:00, 486.60%/s]"
          }
        },
        "c3da34580c2342d597c65787cb15013e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ed05fde48d44ac831cd72e5e249b28",
            "placeholder": "​",
            "style": "IPY_MODEL_47751790b8d94346bf786df2fcaf16b5",
            "value": " 100.0/100 [44:30&lt;00:00,  1.49%/s]"
          }
        },
        "d289f0a2b44a4760ad3deb3e52bd529b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4cec7aa8f144e4bfcbb0dcbf1b1746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70e2c72d9d404f4aa8c2b764e7af7b93",
              "IPY_MODEL_55ecc81af9c44546b8a8140a821003ac",
              "IPY_MODEL_c3da34580c2342d597c65787cb15013e"
            ],
            "layout": "IPY_MODEL_290b8c08c2b648889c5ac98e59efbb70"
          }
        },
        "eb7841f10d1948389920a24690ef421b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d221ca56d12435abfc8f0468f143e7d",
            "placeholder": "​",
            "style": "IPY_MODEL_388614f2882a449fb87e9453b2a7f527",
            "value": "Loading: 100%"
          }
        },
        "fc56e53314f34d18a38afd8cb29fafb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
